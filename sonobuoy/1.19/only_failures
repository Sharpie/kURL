name: e2e
status: failed
meta:
  type: summary
items:
- name: junit_01.xml
  status: failed
  meta:
    file: results/global/junit_01.xml
    type: file
  items:
  - name: Kubernetes e2e suite
    status: failed
    items:
    - name: '[sig-network] Services should be able to change the type from ExternalName
        to NodePort [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 22:15:47.295: Unexpected error:
              <*errors.errorString | 0xc0028ca7c0>: {
                  s: "out-of-range nodePort (40555) for service",
              }
              out-of-range nodePort (40555) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1754
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 22:15:47.224: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should be able to change the type from ExternalName to NodePort [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating a service externalname-service with the type=ExternalName in namespace
          services-5949\nSTEP: changing the ExternalName service to type=NodePort\nAug
          16 22:15:47.295: FAIL: Unexpected error:\n    <*errors.errorString | 0xc0028ca7c0>:
          {\n        s: \"out-of-range nodePort (40555) for service\",\n    }\n    out-of-range
          nodePort (40555) for service\noccurred\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/network.glob..func24.15()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1754
          +0x265\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\nAug 16 22:15:47.296: INFO: Cleaning up the ExternalName to NodePort
          test service\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-5949\".\nSTEP: Found 0 events.\nAug
          16 22:15:47.317: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 22:15:47.317:
          INFO: \nAug 16 22:15:47.319: INFO: \nLogging node info for node kyle-kurl\nAug
          16 22:15:47.321: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 3724 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:09:06 +0000 UTC,LastTransitionTime:2021-08-16 22:09:06 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 22:15:47.322: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 22:15:47.324: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 22:15:47.352: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: envoy-kfmkn started at 2021-08-16 22:10:57 +0000 UTC (1+2 container
          statuses recorded)\nAug 16 22:15:47.354: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: kube-state-metrics-f97897479-dflfv
          started at 2021-08-16 22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 22:15:47.354: INFO: rook-ceph-agent-h9rxz started at 2021-08-16
          22:12:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: rook-ceph-operator-747c86774c-xk84b started at 2021-08-16 22:09:20
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf started at 2021-08-16 22:12:59 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          mgr ready: true, restart count 0\nAug 16 22:15:47.354: INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s
          started at 2021-08-16 22:10:51 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 22:15:47.354: INFO: contour-f85dd8bcb-dlsg2 started at 2021-08-16 22:10:57
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer contour ready: true, restart count 0\nAug 16 22:15:47.354: INFO:
          kube-controller-manager-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          kube-controller-manager ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: ekc-operator-5888598d79-slz82 started at 2021-08-16 22:11:17 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 22:15:47.354: INFO: prometheus-k8s-0
          started at 2021-08-16 22:11:21 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 22:15:47.354: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:15:47.354: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:15:47.354: INFO: etcd-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354:
          INFO: \tContainer etcd ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: kube-apiserver-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          kube-apiserver ready: true, restart count 0\nAug 16 22:15:47.354: INFO:
          weave-net-vzk6c started at 2021-08-16 22:09:01 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer weave ready:
          true, restart count 1\nAug 16 22:15:47.354: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: contour-certgen-v1.18.0-ptzsl
          started at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer contour ready: false, restart count 0\nAug
          16 22:15:47.354: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started at 2021-08-16
          22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 16 22:15:47.354:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: alertmanager-prometheus-alertmanager-0 started at 2021-08-16 22:11:18
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer alertmanager ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer config-reloader ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj started at 2021-08-16 22:12:28 +0000
          UTC (1+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tInit
          container init-mon-fs ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer mon ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: rook-ceph-osd-0-667b79b95b-tkhtg started at 2021-08-16 22:12:59 +0000
          UTC (2+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tInit
          container config-init ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tInit container copy-bins ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer osd ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: contour-f85dd8bcb-sp4l2 started at 2021-08-16 22:10:57 +0000 UTC (0+1
          container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer contour
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: registry-5b5c4668f5-v5crh
          started at 2021-08-16 22:11:00 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 22:15:47.354: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 22:15:47.354: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 22:15:47.354: INFO: registry-5b5c4668f5-5xj9k started
          at 2021-08-16 22:11:00 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 22:15:47.354: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 22:15:47.354: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 22:15:47.354: INFO: prometheus-operator-7f6d8fdc86-rd4q6
          started at 2021-08-16 22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer kube-prometheus-stack ready: true, restart
          count 0\nAug 16 22:15:47.354: INFO: prometheus-node-exporter-nt2kx started
          at 2021-08-16 22:11:15 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer node-exporter ready: true, restart count
          0\nAug 16 22:15:47.354: INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer kube-proxy ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: rook-discover-zqfsh started at 2021-08-16 22:09:21 +0000 UTC (0+1
          container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer rook-discover
          ready: true, restart count 0\nAug 16 22:15:47.354: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:15:47.354: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 22:15:47.354: INFO: coredns-f9fd979d6-2ddtt started at 2021-08-16
          22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: grafana-5b868476b6-5lvkg started at 2021-08-16 22:11:14 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tInit container
          grafana-sc-datasources ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer grafana ready: true, restart count 0\nAug 16 22:15:47.354:
          INFO: \tContainer grafana-sc-dashboard ready: true, restart count 0\nAug
          16 22:15:47.354: INFO: coredns-f9fd979d6-zq6fp started at 2021-08-16 22:09:12
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO:
          \tContainer coredns ready: true, restart count 0\nAug 16 22:15:47.354: INFO:
          prometheus-adapter-75c7788d57-5rfg2 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          prometheus-adapter ready: true, restart count 0\nAug 16 22:15:47.354: INFO:
          rook-ceph-osd-prepare-kyle-kurl-9x275 started at 2021-08-16 22:13:24 +0000
          UTC (0+2 container statuses recorded)\nAug 16 22:15:47.354: INFO: \tContainer
          copy-bins ready: false, restart count 0\nAug 16 22:15:47.354: INFO: \tContainer
          provision ready: false, restart count 0\nAug 16 22:15:47.402: INFO: \nLatency
          metrics for node kyle-kurl\nAug 16 22:15:47.402: INFO: Waiting up to 3m0s
          for all (but 0) nodes to be ready\nSTEP: Destroying namespace \"services-5949\"
          for this suite.\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-network] Services should have session affinity work for NodePort
        service [LinuxOnly] [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 22:16:57.128: Unexpected error:
              <*errors.errorString | 0xc0008a9c00>: {
                  s: "out-of-range nodePort (41343) for service",
              }
              out-of-range nodePort (41343) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3511
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 22:16:49.021: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should have session affinity work for NodePort service [LinuxOnly] [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating service in namespace services-5385\nSTEP: creating service affinity-nodeport
          in namespace services-5385\nSTEP: creating replication controller affinity-nodeport
          in namespace services-5385\nAug 16 22:16:55.119: INFO: Creating new exec
          pod\nAug 16 22:16:57.128: FAIL: Unexpected error:\n    <*errors.errorString
          | 0xc0008a9c00>: {\n        s: \"out-of-range nodePort (41343) for service\",\n
          \   }\n    out-of-range nodePort (41343) for service\noccurred\n\nFull Stack
          Trace\nk8s.io/kubernetes/test/e2e/network.execAffinityTestForNonLBServiceWithOptionalTransition(0xc000bb2b00,
          0x5411460, 0xc002800580, 0xc00087e000, 0x0)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3511
          +0x62e\nk8s.io/kubernetes/test/e2e/network.execAffinityTestForNonLBService(...)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3470\nk8s.io/kubernetes/test/e2e/network.glob..func24.28()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:2508
          +0xa5\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\nAug 16 22:16:57.129: INFO: Cleaning up the exec pod\nSTEP: deleting
          ReplicationController affinity-nodeport in namespace services-5385, will
          wait for the garbage collector to delete the pods\nAug 16 22:16:57.200:
          INFO: Deleting ReplicationController affinity-nodeport took: 5.560194ms\nAug
          16 22:16:58.000: INFO: Terminating ReplicationController affinity-nodeport
          pods took: 800.243065ms\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-5385\".\nSTEP: Found 23 events.\nAug
          16 22:17:08.125: INFO: At 2021-08-16 22:16:49 +0000 UTC - event for affinity-nodeport:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-xd7fq\nAug
          16 22:17:08.125: INFO: At 2021-08-16 22:16:49 +0000 UTC - event for affinity-nodeport:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-dfhz5\nAug
          16 22:17:08.125: INFO: At 2021-08-16 22:16:49 +0000 UTC - event for affinity-nodeport:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-4xk5j\nAug
          16 22:17:08.125: INFO: At 2021-08-16 22:16:49 +0000 UTC - event for affinity-nodeport-4xk5j:
          {default-scheduler } Scheduled: Successfully assigned services-5385/affinity-nodeport-4xk5j
          to kyle-kurl\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:49 +0000 UTC
          - event for affinity-nodeport-dfhz5: {default-scheduler } Scheduled: Successfully
          assigned services-5385/affinity-nodeport-dfhz5 to kyle-kurl\nAug 16 22:17:08.125:
          INFO: At 2021-08-16 22:16:49 +0000 UTC - event for affinity-nodeport-xd7fq:
          {default-scheduler } Scheduled: Successfully assigned services-5385/affinity-nodeport-xd7fq
          to kyle-kurl\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:50 +0000 UTC
          - event for affinity-nodeport-4xk5j: {kubelet kyle-kurl} Started: Started
          container affinity-nodeport\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:50
          +0000 UTC - event for affinity-nodeport-4xk5j: {kubelet kyle-kurl} Pulled:
          Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\" already present
          on machine\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:50 +0000 UTC
          - event for affinity-nodeport-4xk5j: {kubelet kyle-kurl} Created: Created
          container affinity-nodeport\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:50
          +0000 UTC - event for affinity-nodeport-dfhz5: {kubelet kyle-kurl} Created:
          Created container affinity-nodeport\nAug 16 22:17:08.125: INFO: At 2021-08-16
          22:16:50 +0000 UTC - event for affinity-nodeport-dfhz5: {kubelet kyle-kurl}
          Started: Started container affinity-nodeport\nAug 16 22:17:08.125: INFO:
          At 2021-08-16 22:16:50 +0000 UTC - event for affinity-nodeport-dfhz5: {kubelet
          kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:51
          +0000 UTC - event for affinity-nodeport-xd7fq: {kubelet kyle-kurl} Created:
          Created container affinity-nodeport\nAug 16 22:17:08.125: INFO: At 2021-08-16
          22:16:51 +0000 UTC - event for affinity-nodeport-xd7fq: {kubelet kyle-kurl}
          Started: Started container affinity-nodeport\nAug 16 22:17:08.125: INFO:
          At 2021-08-16 22:16:51 +0000 UTC - event for affinity-nodeport-xd7fq: {kubelet
          kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:55
          +0000 UTC - event for execpod-affinity2xh6m: {default-scheduler } Scheduled:
          Successfully assigned services-5385/execpod-affinity2xh6m to kyle-kurl\nAug
          16 22:17:08.125: INFO: At 2021-08-16 22:16:55 +0000 UTC - event for execpod-affinity2xh6m:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:17:08.125: INFO: At 2021-08-16 22:16:55
          +0000 UTC - event for execpod-affinity2xh6m: {kubelet kyle-kurl} Created:
          Created container agnhost-container\nAug 16 22:17:08.125: INFO: At 2021-08-16
          22:16:56 +0000 UTC - event for execpod-affinity2xh6m: {kubelet kyle-kurl}
          Started: Started container agnhost-container\nAug 16 22:17:08.125: INFO:
          At 2021-08-16 22:16:57 +0000 UTC - event for affinity-nodeport-4xk5j: {kubelet
          kyle-kurl} Killing: Stopping container affinity-nodeport\nAug 16 22:17:08.125:
          INFO: At 2021-08-16 22:16:57 +0000 UTC - event for affinity-nodeport-dfhz5:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport\nAug 16
          22:17:08.125: INFO: At 2021-08-16 22:16:57 +0000 UTC - event for affinity-nodeport-xd7fq:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport\nAug 16
          22:17:08.125: INFO: At 2021-08-16 22:16:57 +0000 UTC - event for execpod-affinity2xh6m:
          {kubelet kyle-kurl} Killing: Stopping container agnhost-container\nAug 16
          22:17:08.127: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 22:17:08.127:
          INFO: \nAug 16 22:17:08.129: INFO: \nLogging node info for node kyle-kurl\nAug
          16 22:17:08.131: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 3724 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:09:06 +0000 UTC,LastTransitionTime:2021-08-16 22:09:06 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          22:15:19 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 22:17:08.131: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 22:17:08.134: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 22:17:08.148: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:17:08.148: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:17:08.148: INFO: kube-controller-manager-kyle-kurl
          started at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer kube-controller-manager ready: true,
          restart count 0\nAug 16 22:17:08.148: INFO: ekc-operator-5888598d79-slz82
          started at 2021-08-16 22:11:17 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer ekc-operator ready: true, restart count
          0\nAug 16 22:17:08.148: INFO: prometheus-k8s-0 started at 2021-08-16 22:11:21
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:17:08.148: INFO:
          \tInit container init-config-reloader ready: true, restart count 0\nAug
          16 22:17:08.148: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 22:17:08.148: INFO: \tContainer prometheus ready: true,
          restart count 0\nAug 16 22:17:08.148: INFO: contour-certgen-v1.18.0-ptzsl
          started at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer contour ready: false, restart count 0\nAug
          16 22:17:08.148: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started at 2021-08-16
          22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 16 22:17:08.148:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 22:17:08.148: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 22:17:08.148: INFO: kube-apiserver-kyle-kurl started
          at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 22:17:08.148: INFO: weave-net-vzk6c started at 2021-08-16 22:09:01
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:17:08.148: INFO:
          \tContainer weave ready: true, restart count 1\nAug 16 22:17:08.148: INFO:
          \tContainer weave-npc ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: alertmanager-prometheus-alertmanager-0 started at 2021-08-16 22:11:18
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:17:08.148: INFO:
          \tContainer alertmanager ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer config-reloader ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj started at 2021-08-16 22:12:28 +0000
          UTC (1+1 container statuses recorded)\nAug 16 22:17:08.148: INFO: \tInit
          container init-mon-fs ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer mon ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: rook-ceph-osd-0-667b79b95b-tkhtg started at 2021-08-16 22:12:59 +0000
          UTC (2+1 container statuses recorded)\nAug 16 22:17:08.148: INFO: \tInit
          container config-init ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tInit container copy-bins ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer osd ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: prometheus-node-exporter-nt2kx started at 2021-08-16 22:11:15 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:17:08.148: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 22:17:08.148: INFO: contour-f85dd8bcb-sp4l2
          started at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.148: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 22:17:08.148: INFO: registry-5b5c4668f5-v5crh started at 2021-08-16 22:11:00
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:17:08.148: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 22:17:08.148:
          INFO: registry-5b5c4668f5-5xj9k started at 2021-08-16 22:11:00 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:17:08.148: INFO: \tInit container
          restore ready: true, restart count 0\nAug 16 22:17:08.148: INFO: \tContainer
          registry ready: true, restart count 0\nAug 16 22:17:08.148: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 16 22:17:08.149: INFO:
          prometheus-operator-7f6d8fdc86-rd4q6 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer
          kube-prometheus-stack ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: grafana-5b868476b6-5lvkg started at 2021-08-16 22:11:14 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tInit container
          grafana-sc-datasources ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: \tContainer grafana ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: \tContainer grafana-sc-dashboard ready: true, restart count 0\nAug
          16 22:17:08.149: INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer
          kube-proxy ready: true, restart count 0\nAug 16 22:17:08.149: INFO: rook-discover-zqfsh
          started at 2021-08-16 22:09:21 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.149: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 22:17:08.149: INFO: sonobuoy started at 2021-08-16 22:12:42 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer
          kube-sonobuoy ready: true, restart count 0\nAug 16 22:17:08.149: INFO: coredns-f9fd979d6-2ddtt
          started at 2021-08-16 22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.149: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 22:17:08.149: INFO: coredns-f9fd979d6-zq6fp started at 2021-08-16 22:09:12
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149: INFO:
          \tContainer coredns ready: true, restart count 0\nAug 16 22:17:08.149: INFO:
          prometheus-adapter-75c7788d57-5rfg2 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer
          prometheus-adapter ready: true, restart count 0\nAug 16 22:17:08.149: INFO:
          rook-ceph-osd-prepare-kyle-kurl-9x275 started at 2021-08-16 22:13:24 +0000
          UTC (0+2 container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer
          copy-bins ready: false, restart count 0\nAug 16 22:17:08.149: INFO: \tContainer
          provision ready: false, restart count 0\nAug 16 22:17:08.149: INFO: rook-ceph-agent-h9rxz
          started at 2021-08-16 22:12:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:17:08.149: INFO: \tContainer rook-ceph-agent ready: true, restart
          count 0\nAug 16 22:17:08.149: INFO: kube-scheduler-kyle-kurl started at
          2021-08-16 22:08:49 +0000 UTC (0+1 container statuses recorded)\nAug 16
          22:17:08.149: INFO: \tContainer kube-scheduler ready: true, restart count
          0\nAug 16 22:17:08.149: INFO: envoy-kfmkn started at 2021-08-16 22:10:57
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:17:08.149: INFO:
          \tInit container envoy-initconfig ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: \tContainer envoy ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: \tContainer shutdown-manager ready: true, restart count 0\nAug 16
          22:17:08.149: INFO: kube-state-metrics-f97897479-dflfv started at 2021-08-16
          22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149:
          INFO: \tContainer kube-state-metrics ready: true, restart count 0\nAug 16
          22:17:08.149: INFO: rook-ceph-operator-747c86774c-xk84b started at 2021-08-16
          22:09:20 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149:
          INFO: \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16
          22:17:08.149: INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf started at 2021-08-16
          22:12:59 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149:
          INFO: \tContainer mgr ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s started at 2021-08-16
          22:10:51 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:17:08.149:
          INFO: \tContainer rgw ready: true, restart count 0\nAug 16 22:17:08.149:
          INFO: contour-f85dd8bcb-dlsg2 started at 2021-08-16 22:10:57 +0000 UTC (0+1
          container statuses recorded)\nAug 16 22:17:08.149: INFO: \tContainer contour
          ready: true, restart count 0\nAug 16 22:17:08.193: INFO: \nLatency metrics
          for node kyle-kurl\nAug 16 22:17:08.193: INFO: Waiting up to 3m0s for all
          (but 0) nodes to be ready\nSTEP: Destroying namespace \"services-5385\"
          for this suite.\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-scheduling] SchedulerPredicates [Serial] validates resource limits
        of pods that are allowed to run  [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 22:42:24.619: Timed out after 10m0s waiting for stable cluster.
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:55
        system-out: "[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 22:32:22.568: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          sched-pred\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90\nAug
          16 22:32:22.591: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready\nAug
          16 22:32:22.595: INFO: Waiting for terminating namespaces to be deleted...\nAug
          16 22:32:22.597: INFO: \nLogging pods the apiserver thinks is on node kyle-kurl
          before test\nAug 16 22:32:22.613: INFO: annotationupdatee76f449b-be1f-4f6f-a4a2-d66f99d4a352
          from downward-api-165 started at 2021-08-16 22:32:10 +0000 UTC (1 container
          statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer client-container
          ready: false, restart count 0\nAug 16 22:32:22.613: INFO: coredns-f9fd979d6-2ddtt
          from kube-system started at 2021-08-16 22:09:12 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer coredns ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: coredns-f9fd979d6-zq6fp from kube-system
          started at 2021-08-16 22:09:12 +0000 UTC (1 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 22:32:22.613: INFO: etcd-kyle-kurl from kube-system started at 2021-08-16
          22:08:48 +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613:
          INFO: \tContainer etcd ready: true, restart count 0\nAug 16 22:32:22.613:
          INFO: kube-apiserver-kyle-kurl from kube-system started at 2021-08-16 22:08:48
          +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer
          kube-apiserver ready: true, restart count 0\nAug 16 22:32:22.613: INFO:
          kube-controller-manager-kyle-kurl from kube-system started at 2021-08-16
          22:08:48 +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 22:32:22.613: INFO: kube-proxy-gpjcf from kube-system started at 2021-08-16
          22:08:56 +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613:
          INFO: \tContainer kube-proxy ready: true, restart count 0\nAug 16 22:32:22.613:
          INFO: kube-scheduler-kyle-kurl from kube-system started at 2021-08-16 22:08:49
          +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer
          kube-scheduler ready: true, restart count 0\nAug 16 22:32:22.613: INFO:
          weave-net-vzk6c from kube-system started at 2021-08-16 22:09:01 +0000 UTC
          (2 container statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer
          weave ready: true, restart count 1\nAug 16 22:32:22.613: INFO: \tContainer
          weave-npc ready: true, restart count 0\nAug 16 22:32:22.613: INFO: ekc-operator-5888598d79-slz82
          from kurl started at 2021-08-16 22:11:17 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer ekc-operator ready: true,
          restart count 0\nAug 16 22:32:22.613: INFO: registry-5b5c4668f5-5xj9k from
          kurl started at 2021-08-16 22:11:00 +0000 UTC (2 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer registry ready: true, restart count 0\nAug
          16 22:32:22.613: INFO: \tContainer registry-backup ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: registry-5b5c4668f5-v5crh from kurl
          started at 2021-08-16 22:11:00 +0000 UTC (2 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer registry ready: true, restart count 0\nAug
          16 22:32:22.613: INFO: \tContainer registry-backup ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: alertmanager-prometheus-alertmanager-0
          from monitoring started at 2021-08-16 22:11:18 +0000 UTC (2 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer alertmanager ready: true,
          restart count 0\nAug 16 22:32:22.613: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 22:32:22.613: INFO: grafana-5b868476b6-5lvkg
          from monitoring started at 2021-08-16 22:11:14 +0000 UTC (2 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer grafana ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: \tContainer grafana-sc-dashboard ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: kube-state-metrics-f97897479-dflfv
          from monitoring started at 2021-08-16 22:11:14 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer kube-state-metrics ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: prometheus-adapter-75c7788d57-5rfg2
          from monitoring started at 2021-08-16 22:11:14 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer prometheus-adapter ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: prometheus-k8s-0 from
          monitoring started at 2021-08-16 22:11:21 +0000 UTC (2 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer config-reloader ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 22:32:22.613: INFO: prometheus-node-exporter-nt2kx
          from monitoring started at 2021-08-16 22:11:15 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer node-exporter ready: true,
          restart count 0\nAug 16 22:32:22.613: INFO: prometheus-operator-7f6d8fdc86-rd4q6
          from monitoring started at 2021-08-16 22:11:14 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer kube-prometheus-stack
          ready: true, restart count 0\nAug 16 22:32:22.613: INFO: contour-certgen-v1.18.0-ptzsl
          from projectcontour started at 2021-08-16 22:10:57 +0000 UTC (1 container
          statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer contour ready:
          false, restart count 0\nAug 16 22:32:22.613: INFO: contour-f85dd8bcb-dlsg2
          from projectcontour started at 2021-08-16 22:10:57 +0000 UTC (1 container
          statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer contour ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: contour-f85dd8bcb-sp4l2
          from projectcontour started at 2021-08-16 22:10:57 +0000 UTC (1 container
          statuses recorded)\nAug 16 22:32:22.613: INFO: \tContainer contour ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: envoy-kfmkn from projectcontour
          started at 2021-08-16 22:10:57 +0000 UTC (2 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer envoy ready: true, restart count 0\nAug
          16 22:32:22.613: INFO: \tContainer shutdown-manager ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-ceph-agent-h9rxz from rook-ceph
          started at 2021-08-16 22:12:48 +0000 UTC (1 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer rook-ceph-agent ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf from
          rook-ceph started at 2021-08-16 22:12:59 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer mgr ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj from
          rook-ceph started at 2021-08-16 22:12:28 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-ceph-operator-747c86774c-xk84b
          from rook-ceph started at 2021-08-16 22:09:20 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer rook-ceph-operator ready:
          true, restart count 0\nAug 16 22:32:22.613: INFO: rook-ceph-osd-0-667b79b95b-tkhtg
          from rook-ceph started at 2021-08-16 22:12:59 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer osd ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-ceph-osd-prepare-kyle-kurl-9x275
          from rook-ceph started at 2021-08-16 22:13:24 +0000 UTC (2 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer copy-bins ready: false,
          restart count 0\nAug 16 22:32:22.613: INFO: \tContainer provision ready:
          false, restart count 0\nAug 16 22:32:22.613: INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s
          from rook-ceph started at 2021-08-16 22:10:51 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer rgw ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: rook-discover-zqfsh from rook-ceph started
          at 2021-08-16 22:09:21 +0000 UTC (1 container statuses recorded)\nAug 16
          22:32:22.613: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 22:32:22.613: INFO: sonobuoy from sonobuoy started at 2021-08-16
          22:12:42 +0000 UTC (1 container statuses recorded)\nAug 16 22:32:22.613:
          INFO: \tContainer kube-sonobuoy ready: true, restart count 0\nAug 16 22:32:22.613:
          INFO: sonobuoy-e2e-job-587c54c6a51d4b83 from sonobuoy started at 2021-08-16
          22:12:46 +0000 UTC (2 container statuses recorded)\nAug 16 22:32:22.613:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 16 22:32:22.613:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 16 22:32:22.613:
          INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d from sonobuoy
          started at 2021-08-16 22:12:46 +0000 UTC (2 container statuses recorded)\nAug
          16 22:32:22.613: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:32:22.613: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:32:22.613: INFO: sample-webhook-deployment-cbccbf6bb-nhsk2
          from webhook-4 started at 2021-08-16 22:32:17 +0000 UTC (1 container statuses
          recorded)\nAug 16 22:32:22.613: INFO: \tContainer sample-webhook ready:
          true, restart count 0\n[It] validates resource limits of pods that are allowed
          to run  [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nAug
          16 22:42:24.618: INFO: Timed out waiting for the following pods to schedule\nAug
          16 22:42:24.619: INFO: monitoring/alertmanager-prometheus-alertmanager-1\nAug
          16 22:42:24.619: INFO: monitoring/alertmanager-prometheus-alertmanager-2\nAug
          16 22:42:24.619: INFO: monitoring/prometheus-k8s-1\nAug 16 22:42:24.619:
          FAIL: Timed out after 10m0s waiting for stable cluster.\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/scheduling.WaitForStableCluster(0x5411460,
          0xc0028111e0, 0xc0008b78c0, 0x4)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:55
          +0x405\nk8s.io/kubernetes/test/e2e/scheduling.glob..func4.5()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:323
          +0xb4\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"sched-pred-5764\".\nSTEP: Found 0 events.\nAug
          16 22:42:24.624: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 22:42:24.624:
          INFO: \nAug 16 22:42:24.626: INFO: \nLogging node info for node kyle-kurl\nAug
          16 22:42:24.628: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 12736 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:09:06 +0000 UTC,LastTransitionTime:2021-08-16 22:09:06 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:37:53 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:37:53 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:37:53 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          22:37:53 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 22:42:24.628: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 22:42:24.631: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 22:42:24.657: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started at 2021-08-16
          22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 16 22:42:24.657:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 22:42:24.657: INFO: kube-apiserver-kyle-kurl started
          at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 22:42:24.657: INFO: weave-net-vzk6c started at 2021-08-16 22:09:01
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tContainer weave ready: true, restart count 1\nAug 16 22:42:24.657: INFO:
          \tContainer weave-npc ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: contour-certgen-v1.18.0-ptzsl started at 2021-08-16 22:10:57 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          contour ready: false, restart count 0\nAug 16 22:42:24.657: INFO: alertmanager-prometheus-alertmanager-0
          started at 2021-08-16 22:11:18 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 22:42:24.657: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj started
          at 2021-08-16 22:12:28 +0000 UTC (1+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: rook-ceph-osd-0-667b79b95b-tkhtg started
          at 2021-08-16 22:12:59 +0000 UTC (2+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tInit container config-init ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: \tInit container copy-bins ready: true,
          restart count 0\nAug 16 22:42:24.657: INFO: \tContainer osd ready: true,
          restart count 0\nAug 16 22:42:24.657: INFO: contour-f85dd8bcb-sp4l2 started
          at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 22:42:24.657: INFO: registry-5b5c4668f5-v5crh started at 2021-08-16 22:11:00
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: registry-5b5c4668f5-5xj9k started at 2021-08-16 22:11:00 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tInit container
          restore ready: true, restart count 0\nAug 16 22:42:24.657: INFO: \tContainer
          registry ready: true, restart count 0\nAug 16 22:42:24.657: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 16 22:42:24.657: INFO:
          prometheus-operator-7f6d8fdc86-rd4q6 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          kube-prometheus-stack ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: prometheus-node-exporter-nt2kx started at 2021-08-16 22:11:15 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 22:42:24.657: INFO: kube-proxy-gpjcf
          started at 2021-08-16 22:08:56 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer kube-proxy ready: true, restart count
          0\nAug 16 22:42:24.657: INFO: rook-discover-zqfsh started at 2021-08-16
          22:09:21 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657:
          INFO: \tContainer rook-discover ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: sonobuoy started at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses
          recorded)\nAug 16 22:42:24.657: INFO: \tContainer kube-sonobuoy ready: true,
          restart count 0\nAug 16 22:42:24.657: INFO: coredns-f9fd979d6-2ddtt started
          at 2021-08-16 22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 22:42:24.657: INFO: grafana-5b868476b6-5lvkg started at 2021-08-16 22:11:14
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tInit container grafana-sc-datasources ready: true, restart count 0\nAug
          16 22:42:24.657: INFO: \tContainer grafana ready: true, restart count 0\nAug
          16 22:42:24.657: INFO: \tContainer grafana-sc-dashboard ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: coredns-f9fd979d6-zq6fp started at 2021-08-16
          22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: prometheus-adapter-75c7788d57-5rfg2 started at 2021-08-16 22:11:14
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tContainer prometheus-adapter ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: rook-ceph-osd-prepare-kyle-kurl-9x275 started at 2021-08-16 22:13:24
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tContainer copy-bins ready: false, restart count 0\nAug 16 22:42:24.657:
          INFO: \tContainer provision ready: false, restart count 0\nAug 16 22:42:24.657:
          INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          kube-scheduler ready: true, restart count 0\nAug 16 22:42:24.657: INFO:
          envoy-kfmkn started at 2021-08-16 22:10:57 +0000 UTC (1+2 container statuses
          recorded)\nAug 16 22:42:24.657: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 16 22:42:24.657: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 16 22:42:24.657: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 16 22:42:24.657: INFO: kube-state-metrics-f97897479-dflfv
          started at 2021-08-16 22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 22:42:24.657: INFO: rook-ceph-agent-h9rxz started at 2021-08-16
          22:12:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: rook-ceph-operator-747c86774c-xk84b started at 2021-08-16 22:09:20
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 22:42:24.657:
          INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf started at 2021-08-16 22:12:59 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          mgr ready: true, restart count 0\nAug 16 22:42:24.657: INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s
          started at 2021-08-16 22:10:51 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:42:24.657: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 22:42:24.657: INFO: contour-f85dd8bcb-dlsg2 started at 2021-08-16 22:10:57
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO:
          \tContainer contour ready: true, restart count 0\nAug 16 22:42:24.657: INFO:
          kube-controller-manager-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:42:24.657: INFO: \tContainer
          kube-controller-manager ready: true, restart count 0\nAug 16 22:42:24.658:
          INFO: ekc-operator-5888598d79-slz82 started at 2021-08-16 22:11:17 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:42:24.658: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 22:42:24.658: INFO: prometheus-k8s-0
          started at 2021-08-16 22:11:21 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:42:24.658: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 22:42:24.658: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 22:42:24.658: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 22:42:24.658: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:42:24.658: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:42:24.658: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:42:24.687: INFO: \nLatency metrics for node kyle-kurl\nAug
          16 22:42:24.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP:
          Destroying namespace \"sched-pred-5764\" for this suite.\n[AfterEach] [sig-scheduling]
          SchedulerPredicates [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81\n"
    - name: '[sig-network] Services should be able to switch session affinity for
        NodePort service [LinuxOnly] [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 22:52:52.783: Unexpected error:
              <*errors.errorString | 0xc002b5a160>: {
                  s: "out-of-range nodePort (19018) for service",
              }
              out-of-range nodePort (19018) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3511
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 22:52:44.672: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should be able to switch session affinity for NodePort service [LinuxOnly]
          [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating service in namespace services-7001\nSTEP: creating service affinity-nodeport-transition
          in namespace services-7001\nSTEP: creating replication controller affinity-nodeport-transition
          in namespace services-7001\nAug 16 22:52:50.771: INFO: Creating new exec
          pod\nAug 16 22:52:52.783: FAIL: Unexpected error:\n    <*errors.errorString
          | 0xc002b5a160>: {\n        s: \"out-of-range nodePort (19018) for service\",\n
          \   }\n    out-of-range nodePort (19018) for service\noccurred\n\nFull Stack
          Trace\nk8s.io/kubernetes/test/e2e/network.execAffinityTestForNonLBServiceWithOptionalTransition(0xc000bb2b00,
          0x5411460, 0xc0011ffe40, 0xc005306000, 0x1)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3511
          +0x62e\nk8s.io/kubernetes/test/e2e/network.execAffinityTestForNonLBServiceWithTransition(...)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3466\nk8s.io/kubernetes/test/e2e/network.glob..func24.30()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:2541
          +0xa5\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\nAug 16 22:52:52.783: INFO: Cleaning up the exec pod\nSTEP: deleting
          ReplicationController affinity-nodeport-transition in namespace services-7001,
          will wait for the garbage collector to delete the pods\nAug 16 22:52:52.849:
          INFO: Deleting ReplicationController affinity-nodeport-transition took:
          5.296824ms\nAug 16 22:52:53.649: INFO: Terminating ReplicationController
          affinity-nodeport-transition pods took: 800.269095ms\n[AfterEach] [sig-network]
          Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-7001\".\nSTEP: Found 24 events.\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC - event for affinity-nodeport-transition:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-transition-r5hr8\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC - event for affinity-nodeport-transition:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-transition-6qct4\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC - event for affinity-nodeport-transition:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-transition-h278w\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC - event for affinity-nodeport-transition-6qct4:
          {default-scheduler } Scheduled: Successfully assigned services-7001/affinity-nodeport-transition-6qct4
          to kyle-kurl\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC
          - event for affinity-nodeport-transition-h278w: {default-scheduler } Scheduled:
          Successfully assigned services-7001/affinity-nodeport-transition-h278w to
          kyle-kurl\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:44 +0000 UTC -
          event for affinity-nodeport-transition-r5hr8: {default-scheduler } Scheduled:
          Successfully assigned services-7001/affinity-nodeport-transition-r5hr8 to
          kyle-kurl\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:45 +0000 UTC -
          event for affinity-nodeport-transition-h278w: {kubelet kyle-kurl} Pulled:
          Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\" already present
          on machine\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:45 +0000 UTC
          - event for affinity-nodeport-transition-h278w: {kubelet kyle-kurl} Created:
          Created container affinity-nodeport-transition\nAug 16 22:53:08.167: INFO:
          At 2021-08-16 22:52:45 +0000 UTC - event for affinity-nodeport-transition-h278w:
          {kubelet kyle-kurl} Started: Started container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:46 +0000 UTC - event for affinity-nodeport-transition-r5hr8:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:46
          +0000 UTC - event for affinity-nodeport-transition-r5hr8: {kubelet kyle-kurl}
          Started: Started container affinity-nodeport-transition\nAug 16 22:53:08.167:
          INFO: At 2021-08-16 22:52:46 +0000 UTC - event for affinity-nodeport-transition-r5hr8:
          {kubelet kyle-kurl} Created: Created container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:47 +0000 UTC - event for affinity-nodeport-transition-6qct4:
          {kubelet kyle-kurl} Started: Started container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:47 +0000 UTC - event for affinity-nodeport-transition-6qct4:
          {kubelet kyle-kurl} Created: Created container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:47 +0000 UTC - event for affinity-nodeport-transition-6qct4:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:50
          +0000 UTC - event for execpod-affinity8pr4r: {default-scheduler } Scheduled:
          Successfully assigned services-7001/execpod-affinity8pr4r to kyle-kurl\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:51 +0000 UTC - event for execpod-affinity8pr4r:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 22:53:08.167: INFO: At 2021-08-16 22:52:51
          +0000 UTC - event for execpod-affinity8pr4r: {kubelet kyle-kurl} Created:
          Created container agnhost-container\nAug 16 22:53:08.167: INFO: At 2021-08-16
          22:52:51 +0000 UTC - event for execpod-affinity8pr4r: {kubelet kyle-kurl}
          Started: Started container agnhost-container\nAug 16 22:53:08.167: INFO:
          At 2021-08-16 22:52:52 +0000 UTC - event for execpod-affinity8pr4r: {kubelet
          kyle-kurl} Killing: Stopping container agnhost-container\nAug 16 22:53:08.167:
          INFO: At 2021-08-16 22:52:53 +0000 UTC - event for affinity-nodeport-transition-6qct4:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:53 +0000 UTC - event for affinity-nodeport-transition-h278w:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:53 +0000 UTC - event for affinity-nodeport-transition-r5hr8:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport-transition\nAug
          16 22:53:08.167: INFO: At 2021-08-16 22:52:53 +0000 UTC - event for execpod-affinity8pr4r:
          {kubelet kyle-kurl} SandboxChanged: Pod sandbox changed, it will be killed
          and re-created.\nAug 16 22:53:08.169: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug
          16 22:53:08.169: INFO: \nAug 16 22:53:08.171: INFO: \nLogging node info
          for node kyle-kurl\nAug 16 22:53:08.173: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl
          \  /api/v1/nodes/kyle-kurl fa8d53a9-9416-47dd-8071-ca25c7b20a51 17510 0
          2021-08-16 22:08:45 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64
          beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl
          kubernetes.io/os:linux kurl.sh/cluster:true node-role.kubernetes.io/master:]
          map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock node.alpha.kubernetes.io/ttl:0
          volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{kubelet
          Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:09:06 +0000 UTC,LastTransitionTime:2021-08-16 22:09:06 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 22:53:08.174: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 22:53:08.177: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 22:53:08.191: INFO: kube-controller-manager-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.191:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 22:53:08.191: INFO: ekc-operator-5888598d79-slz82 started at 2021-08-16
          22:11:17 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.191:
          INFO: \tContainer ekc-operator ready: true, restart count 0\nAug 16 22:53:08.191:
          INFO: prometheus-k8s-0 started at 2021-08-16 22:11:21 +0000 UTC (1+2 container
          statuses recorded)\nAug 16 22:53:08.191: INFO: \tInit container init-config-reloader
          ready: true, restart count 0\nAug 16 22:53:08.191: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 22:53:08.191: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 22:53:08.191: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:53:08.191: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:53:08.191: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:53:08.191: INFO: sonobuoy-e2e-job-587c54c6a51d4b83
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:53:08.191: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 22:53:08.191: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:53:08.191: INFO: etcd-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.191:
          INFO: \tContainer etcd ready: true, restart count 0\nAug 16 22:53:08.191:
          INFO: kube-apiserver-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:53:08.191: INFO: \tContainer
          kube-apiserver ready: true, restart count 0\nAug 16 22:53:08.191: INFO:
          weave-net-vzk6c started at 2021-08-16 22:09:01 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 22:53:08.191: INFO: \tContainer weave ready:
          true, restart count 1\nAug 16 22:53:08.191: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 22:53:08.191: INFO: contour-certgen-v1.18.0-ptzsl
          started at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.191: INFO: \tContainer contour ready: false, restart count 0\nAug
          16 22:53:08.191: INFO: alertmanager-prometheus-alertmanager-0 started at
          2021-08-16 22:11:18 +0000 UTC (0+2 container statuses recorded)\nAug 16
          22:53:08.191: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 22:53:08.191: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 22:53:08.191: INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj started
          at 2021-08-16 22:12:28 +0000 UTC (1+1 container statuses recorded)\nAug
          16 22:53:08.191: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 16 22:53:08.191: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 22:53:08.191: INFO: rook-ceph-osd-0-667b79b95b-tkhtg started
          at 2021-08-16 22:12:59 +0000 UTC (2+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tInit container config-init ready: true, restart
          count 0\nAug 16 22:53:08.192: INFO: \tInit container copy-bins ready: true,
          restart count 0\nAug 16 22:53:08.192: INFO: \tContainer osd ready: true,
          restart count 0\nAug 16 22:53:08.192: INFO: contour-f85dd8bcb-sp4l2 started
          at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 22:53:08.192: INFO: registry-5b5c4668f5-v5crh started at 2021-08-16 22:11:00
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: registry-5b5c4668f5-5xj9k started at 2021-08-16 22:11:00 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:53:08.192: INFO: \tInit container
          restore ready: true, restart count 0\nAug 16 22:53:08.192: INFO: \tContainer
          registry ready: true, restart count 0\nAug 16 22:53:08.192: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 16 22:53:08.192: INFO:
          prometheus-operator-7f6d8fdc86-rd4q6 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO: \tContainer
          kube-prometheus-stack ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: prometheus-node-exporter-nt2kx started at 2021-08-16 22:11:15 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 22:53:08.192: INFO: kube-proxy-gpjcf
          started at 2021-08-16 22:08:56 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tContainer kube-proxy ready: true, restart count
          0\nAug 16 22:53:08.192: INFO: rook-discover-zqfsh started at 2021-08-16
          22:09:21 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192:
          INFO: \tContainer rook-discover ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: sonobuoy started at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses
          recorded)\nAug 16 22:53:08.192: INFO: \tContainer kube-sonobuoy ready: true,
          restart count 0\nAug 16 22:53:08.192: INFO: coredns-f9fd979d6-2ddtt started
          at 2021-08-16 22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 22:53:08.192: INFO: grafana-5b868476b6-5lvkg started at 2021-08-16 22:11:14
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tInit container grafana-sc-datasources ready: true, restart count 0\nAug
          16 22:53:08.192: INFO: \tContainer grafana ready: true, restart count 0\nAug
          16 22:53:08.192: INFO: \tContainer grafana-sc-dashboard ready: true, restart
          count 0\nAug 16 22:53:08.192: INFO: coredns-f9fd979d6-zq6fp started at 2021-08-16
          22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: prometheus-adapter-75c7788d57-5rfg2 started at 2021-08-16 22:11:14
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tContainer prometheus-adapter ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: rook-ceph-osd-prepare-kyle-kurl-9x275 started at 2021-08-16 22:13:24
          +0000 UTC (0+2 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tContainer copy-bins ready: false, restart count 0\nAug 16 22:53:08.192:
          INFO: \tContainer provision ready: false, restart count 0\nAug 16 22:53:08.192:
          INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO: \tContainer
          kube-scheduler ready: true, restart count 0\nAug 16 22:53:08.192: INFO:
          send-events-d45b2fca-1795-4862-9799-629c8bc12642 started at 2021-08-16 22:52:32
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tContainer p ready: true, restart count 0\nAug 16 22:53:08.192: INFO: envoy-kfmkn
          started at 2021-08-16 22:10:57 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tInit container envoy-initconfig ready: true, restart
          count 0\nAug 16 22:53:08.192: INFO: \tContainer envoy ready: true, restart
          count 0\nAug 16 22:53:08.192: INFO: \tContainer shutdown-manager ready:
          true, restart count 0\nAug 16 22:53:08.192: INFO: kube-state-metrics-f97897479-dflfv
          started at 2021-08-16 22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 22:53:08.192: INFO: rook-ceph-agent-h9rxz started at 2021-08-16
          22:12:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: rook-ceph-operator-747c86774c-xk84b started at 2021-08-16 22:09:20
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 22:53:08.192:
          INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf started at 2021-08-16 22:12:59 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO: \tContainer
          mgr ready: true, restart count 0\nAug 16 22:53:08.192: INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s
          started at 2021-08-16 22:10:51 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:53:08.192: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 22:53:08.192: INFO: contour-f85dd8bcb-dlsg2 started at 2021-08-16 22:10:57
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:53:08.192: INFO:
          \tContainer contour ready: true, restart count 0\nAug 16 22:53:08.240: INFO:
          \nLatency metrics for node kyle-kurl\nAug 16 22:53:08.240: INFO: Waiting
          up to 3m0s for all (but 0) nodes to be ready\nSTEP: Destroying namespace
          \"services-7001\" for this suite.\n[AfterEach] [sig-network] Services\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-network] Services should be able to change the type from NodePort
        to ExternalName [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 22:54:42.672: Unexpected error:
              <*errors.errorString | 0xc00333a0b0>: {
                  s: "out-of-range nodePort (43882) for service",
              }
              out-of-range nodePort (43882) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1819
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 22:54:42.635: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should be able to change the type from NodePort to ExternalName [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating a service nodeport-service with the type=NodePort in namespace
          services-1852\nAug 16 22:54:42.672: FAIL: Unexpected error:\n    <*errors.errorString
          | 0xc00333a0b0>: {\n        s: \"out-of-range nodePort (43882) for service\",\n
          \   }\n    out-of-range nodePort (43882) for service\noccurred\n\nFull Stack
          Trace\nk8s.io/kubernetes/test/e2e/network.glob..func24.17()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1819
          +0x1a5\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-1852\".\nSTEP: Found 0 events.\nAug
          16 22:54:42.680: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 22:54:42.680:
          INFO: \nAug 16 22:54:42.682: INFO: \nLogging node info for node kyle-kurl\nAug
          16 22:54:42.687: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 17510 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:09:06 +0000 UTC,LastTransitionTime:2021-08-16 22:09:06 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          22:52:56 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 22:54:42.687: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 22:54:42.695: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 22:54:42.712: INFO: coredns-f9fd979d6-zq6fp started at 2021-08-16 22:09:12
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO:
          \tContainer coredns ready: true, restart count 0\nAug 16 22:54:42.712: INFO:
          prometheus-adapter-75c7788d57-5rfg2 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO: \tContainer
          prometheus-adapter ready: true, restart count 0\nAug 16 22:54:42.712: INFO:
          rook-ceph-osd-prepare-kyle-kurl-9x275 started at 2021-08-16 22:13:24 +0000
          UTC (0+2 container statuses recorded)\nAug 16 22:54:42.712: INFO: \tContainer
          copy-bins ready: false, restart count 0\nAug 16 22:54:42.712: INFO: \tContainer
          provision ready: false, restart count 0\nAug 16 22:54:42.712: INFO: kube-scheduler-kyle-kurl
          started at 2021-08-16 22:08:49 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tContainer kube-scheduler ready: true, restart count
          0\nAug 16 22:54:42.712: INFO: test-cleanup-controller-hpj2k started at 2021-08-16
          22:54:37 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712:
          INFO: \tContainer httpd ready: true, restart count 0\nAug 16 22:54:42.712:
          INFO: envoy-kfmkn started at 2021-08-16 22:10:57 +0000 UTC (1+2 container
          statuses recorded)\nAug 16 22:54:42.712: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 16 22:54:42.712: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 16 22:54:42.712: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 16 22:54:42.712: INFO: kube-state-metrics-f97897479-dflfv
          started at 2021-08-16 22:11:14 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 22:54:42.712: INFO: rook-ceph-agent-h9rxz started at 2021-08-16
          22:12:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 22:54:42.712:
          INFO: rook-ceph-operator-747c86774c-xk84b started at 2021-08-16 22:09:20
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 22:54:42.712:
          INFO: rook-ceph-mgr-a-7c8fb8db97-ffvvf started at 2021-08-16 22:12:59 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO: \tContainer
          mgr ready: true, restart count 0\nAug 16 22:54:42.712: INFO: rook-ceph-rgw-rook-ceph-store-a-698d49884c-7nm5s
          started at 2021-08-16 22:10:51 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 22:54:42.712: INFO: contour-f85dd8bcb-dlsg2 started at 2021-08-16 22:10:57
          +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO:
          \tContainer contour ready: true, restart count 0\nAug 16 22:54:42.712: INFO:
          kube-controller-manager-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO: \tContainer
          kube-controller-manager ready: true, restart count 0\nAug 16 22:54:42.712:
          INFO: ekc-operator-5888598d79-slz82 started at 2021-08-16 22:11:17 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.712: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 22:54:42.712: INFO: prometheus-k8s-0
          started at 2021-08-16 22:11:21 +0000 UTC (1+2 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 22:54:42.712: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 22:54:42.712: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 22:54:42.712: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:54:42.712: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 22:54:42.712: INFO: sonobuoy-e2e-job-587c54c6a51d4b83
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 22:54:42.712: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 22:54:42.712: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 22:54:42.712: INFO: etcd-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 22:54:42.713:
          INFO: \tContainer etcd ready: true, restart count 0\nAug 16 22:54:42.713:
          INFO: kube-apiserver-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC
          (0+1 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer
          kube-apiserver ready: true, restart count 0\nAug 16 22:54:42.713: INFO:
          weave-net-vzk6c started at 2021-08-16 22:09:01 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer weave ready:
          true, restart count 1\nAug 16 22:54:42.713: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 22:54:42.713: INFO: contour-certgen-v1.18.0-ptzsl
          started at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tContainer contour ready: false, restart count 0\nAug
          16 22:54:42.713: INFO: alertmanager-prometheus-alertmanager-0 started at
          2021-08-16 22:11:18 +0000 UTC (0+2 container statuses recorded)\nAug 16
          22:54:42.713: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 22:54:42.713: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 22:54:42.713: INFO: rook-ceph-mon-a-6f9b75dbb9-kksgj started
          at 2021-08-16 22:12:28 +0000 UTC (1+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 16 22:54:42.713: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 22:54:42.713: INFO: rook-ceph-osd-0-667b79b95b-tkhtg started
          at 2021-08-16 22:12:59 +0000 UTC (2+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tInit container config-init ready: true, restart
          count 0\nAug 16 22:54:42.713: INFO: \tInit container copy-bins ready: true,
          restart count 0\nAug 16 22:54:42.713: INFO: \tContainer osd ready: true,
          restart count 0\nAug 16 22:54:42.713: INFO: contour-f85dd8bcb-sp4l2 started
          at 2021-08-16 22:10:57 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 22:54:42.713: INFO: registry-5b5c4668f5-v5crh started at 2021-08-16 22:11:00
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:54:42.713: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 22:54:42.713:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 22:54:42.713:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 22:54:42.713:
          INFO: registry-5b5c4668f5-5xj9k started at 2021-08-16 22:11:00 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tInit container
          restore ready: true, restart count 0\nAug 16 22:54:42.713: INFO: \tContainer
          registry ready: true, restart count 0\nAug 16 22:54:42.713: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 16 22:54:42.713: INFO:
          prometheus-operator-7f6d8fdc86-rd4q6 started at 2021-08-16 22:11:14 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer
          kube-prometheus-stack ready: true, restart count 0\nAug 16 22:54:42.713:
          INFO: prometheus-node-exporter-nt2kx started at 2021-08-16 22:11:15 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 22:54:42.713: INFO: test-cleanup-deployment-5d446bdd47-qm7pb
          started at 2021-08-16 22:54:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tContainer agnhost ready: false, restart count 0\nAug
          16 22:54:42.713: INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer
          kube-proxy ready: true, restart count 0\nAug 16 22:54:42.713: INFO: rook-discover-zqfsh
          started at 2021-08-16 22:09:21 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 22:54:42.713: INFO: sonobuoy started at 2021-08-16 22:12:42 +0000
          UTC (0+1 container statuses recorded)\nAug 16 22:54:42.713: INFO: \tContainer
          kube-sonobuoy ready: true, restart count 0\nAug 16 22:54:42.713: INFO: coredns-f9fd979d6-2ddtt
          started at 2021-08-16 22:09:12 +0000 UTC (0+1 container statuses recorded)\nAug
          16 22:54:42.713: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 22:54:42.713: INFO: grafana-5b868476b6-5lvkg started at 2021-08-16 22:11:14
          +0000 UTC (1+2 container statuses recorded)\nAug 16 22:54:42.713: INFO:
          \tInit container grafana-sc-datasources ready: true, restart count 0\nAug
          16 22:54:42.713: INFO: \tContainer grafana ready: true, restart count 0\nAug
          16 22:54:42.713: INFO: \tContainer grafana-sc-dashboard ready: true, restart
          count 0\nAug 16 22:54:42.744: INFO: \nLatency metrics for node kyle-kurl\nAug
          16 22:54:42.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP:
          Destroying namespace \"services-1852\" for this suite.\n[AfterEach] [sig-network]
          Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts
        [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:37:34.503: Conformance test suite needs a cluster with at least 2 nodes.
          Expected
              <int>: 1
          to be >
              <int>: 1
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:423
        system-out: "[BeforeEach] [sig-apps] Daemon set [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:37:34.442: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          daemonsets\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-apps] Daemon set [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134\n[It]
          should rollback without unnecessary restarts [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nAug
          16 23:37:34.503: FAIL: Conformance test suite needs a cluster with at least
          2 nodes.\nExpected\n    <int>: 1\nto be >\n    <int>: 1\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/apps.glob..func3.9()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:423
          +0x27b\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-apps] Daemon set [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100\nAug
          16 23:37:34.509: INFO: daemonset: {\"kind\":\"DaemonSetList\",\"apiVersion\":\"apps/v1\",\"metadata\":{\"selfLink\":\"/apis/apps/v1/namespaces/daemonsets-9780/daemonsets\",\"resourceVersion\":\"33915\"},\"items\":null}\n\nAug
          16 23:37:34.511: INFO: pods: {\"kind\":\"PodList\",\"apiVersion\":\"v1\",\"metadata\":{\"selfLink\":\"/api/v1/namespaces/daemonsets-9780/pods\",\"resourceVersion\":\"33915\"},\"items\":null}\n\n[AfterEach]
          [sig-apps] Daemon set [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"daemonsets-9780\".\nSTEP: Found 0 events.\nAug
          16 23:37:34.520: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 23:37:34.520:
          INFO: \nAug 16 23:37:34.522: INFO: \nLogging node info for node kyle-kurl\nAug
          16 23:37:34.524: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 32796 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:37:34.525: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:37:34.528: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:37:34.548: INFO: kube-controller-manager-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 23:37:34.548: INFO: prometheus-operator-7f6d8fdc86-l8xxq started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer kube-prometheus-stack ready: true, restart count 0\nAug
          16 23:37:34.548: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 23:37:34.548: INFO: registry-5b5c4668f5-bjv6n started
          at 2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:37:34.548: INFO: contour-f85dd8bcb-ddvq5 started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 23:37:34.548: INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548: INFO: \tContainer
          etcd ready: true, restart count 0\nAug 16 23:37:34.548: INFO: kube-apiserver-kyle-kurl
          started at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: envoy-jdqkw started at 2021-08-16 22:56:48
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:37:34.548: INFO:
          \tInit container envoy-initconfig ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: \tContainer envoy ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: \tContainer shutdown-manager ready: true, restart count 0\nAug 16
          23:37:34.548: INFO: rook-ceph-osd-0-667b79b95b-v8lll started at 2021-08-16
          22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tInit container config-init ready: true, restart count 0\nAug 16
          23:37:34.548: INFO: \tInit container copy-bins ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer osd ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5 started at
          2021-08-16 22:55:43 +0000 UTC (1+1 container statuses recorded)\nAug 16
          23:37:34.548: INFO: \tInit container init-mon-fs ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer mon ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started
          at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 23:37:34.548: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer contour ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc started at 2021-08-16 22:57:18
          +0000 UTC (0+2 container statuses recorded)\nAug 16 23:37:34.548: INFO:
          \tContainer copy-bins ready: false, restart count 0\nAug 16 23:37:34.548:
          INFO: \tContainer provision ready: false, restart count 0\nAug 16 23:37:34.548:
          INFO: prometheus-node-exporter-nnn42 started at 2021-08-16 22:55:57 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 23:37:34.548: INFO: rook-discover-f6bdb
          started at 2021-08-16 22:56:06 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: grafana-5b868476b6-jkgng started at 2021-08-16
          22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tInit container grafana-sc-datasources ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer grafana ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer grafana-sc-dashboard ready: true,
          restart count 0\nAug 16 23:37:34.548: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer mgr ready: true, restart count 0\nAug
          16 23:37:34.548: INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548: INFO: \tContainer
          kube-proxy ready: true, restart count 0\nAug 16 23:37:34.548: INFO: prometheus-k8s-0
          started at 2021-08-16 22:56:36 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 23:37:34.548: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:37:34.548: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:37:34.548: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: alertmanager-prometheus-alertmanager-0 started
          at 2021-08-16 22:56:05 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: rook-ceph-agent-vvbln started at 2021-08-16
          22:58:08 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb started at 2021-08-16
          22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer rgw ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: kube-state-metrics-f97897479-rk67g started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548: INFO:
          \tContainer kube-state-metrics ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: registry-5b5c4668f5-mh2mj started at 2021-08-16 22:55:43 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 23:37:34.548: INFO: \tInit container
          restore ready: true, restart count 0\nAug 16 23:37:34.548: INFO: \tContainer
          registry ready: true, restart count 0\nAug 16 23:37:34.548: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 16 23:37:34.548: INFO:
          coredns-f9fd979d6-lq9fv started at 2021-08-16 22:55:43 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:37:34.548: INFO: \tContainer coredns ready:
          true, restart count 0\nAug 16 23:37:34.548: INFO: kube-scheduler-kyle-kurl
          started at 2021-08-16 22:08:49 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer kube-scheduler ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: rook-ceph-operator-747c86774c-9b5zf started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer rook-ceph-operator ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: prometheus-adapter-75c7788d57-5b8h6
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer prometheus-adapter ready: true, restart
          count 0\nAug 16 23:37:34.548: INFO: ekc-operator-5888598d79-nc89z started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:37:34.548: INFO: \tContainer ekc-operator ready: true, restart count
          0\nAug 16 23:37:34.548: INFO: coredns-f9fd979d6-wzvjj started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:37:34.548:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 16 23:37:34.548:
          INFO: weave-net-zf59m started at 2021-08-16 22:55:54 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 23:37:34.548: INFO: \tContainer weave ready:
          true, restart count 2\nAug 16 23:37:34.548: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 23:37:34.589: INFO: \nLatency metrics
          for node kyle-kurl\nAug 16 23:37:34.589: INFO: Waiting up to 3m0s for all
          (but 0) nodes to be ready\nSTEP: Destroying namespace \"daemonsets-9780\"
          for this suite.\n"
          - name: '[sig-network] Services should be able to create a functioning NodePort
        service [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:39:52.824: Unexpected error:
              <*errors.errorString | 0xc004b27030>: {
                  s: "out-of-range nodePort (13341) for service",
              }
              out-of-range nodePort (13341) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1237
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:39:52.770: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should be able to create a functioning NodePort service [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating service nodeport-test with type=NodePort in namespace services-3567\nAug
          16 23:39:52.824: FAIL: Unexpected error:\n    <*errors.errorString | 0xc004b27030>:
          {\n        s: \"out-of-range nodePort (13341) for service\",\n    }\n    out-of-range
          nodePort (13341) for service\noccurred\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/network.glob..func24.11()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1237
          +0x179\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-3567\".\nSTEP: Found 0 events.\nAug
          16 23:39:52.832: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 23:39:52.832:
          INFO: \nAug 16 23:39:52.834: INFO: \nLogging node info for node kyle-kurl\nAug
          16 23:39:52.836: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 32796 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:39:52.837: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:39:52.841: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:39:52.860: INFO: kube-apiserver-kyle-kurl started at 2021-08-16 22:08:48
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO:
          \tContainer kube-apiserver ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: envoy-jdqkw started at 2021-08-16 22:56:48 +0000 UTC (1+2 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-osd-0-667b79b95b-v8lll
          started at 2021-08-16 22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container config-init ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tInit container copy-bins ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: \tContainer osd ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5
          started at 2021-08-16 22:55:43 +0000 UTC (1+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started
          at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer contour ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc
          started at 2021-08-16 22:57:18 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer copy-bins ready: false, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer provision ready: false, restart
          count 0\nAug 16 23:39:52.860: INFO: rook-discover-f6bdb started at 2021-08-16
          22:56:06 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-discover ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: grafana-5b868476b6-jkgng started at 2021-08-16 22:55:43 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tInit container
          grafana-sc-datasources ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: \tContainer grafana ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: \tContainer grafana-sc-dashboard ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer mgr ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: prometheus-node-exporter-nnn42 started at 2021-08-16 22:55:57 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 23:39:52.860: INFO: prometheus-k8s-0
          started at 2021-08-16 22:56:36 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: alertmanager-prometheus-alertmanager-0 started
          at 2021-08-16 22:56:05 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: rook-ceph-agent-vvbln started at 2021-08-16
          22:58:08 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer kube-proxy ready:
          true, restart count 0\nAug 16 23:39:52.860: INFO: kube-state-metrics-f97897479-rk67g
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: registry-5b5c4668f5-mh2mj started at
          2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16
          23:39:52.860: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: coredns-f9fd979d6-lq9fv started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          started at 2021-08-16 22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-operator-747c86774c-9b5zf started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16
          23:39:52.860: INFO: prometheus-adapter-75c7788d57-5b8h6 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer prometheus-adapter ready: true, restart count 0\nAug 16
          23:39:52.860: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: ekc-operator-5888598d79-nc89z started at 2021-08-16 22:55:43 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 23:39:52.860: INFO: coredns-f9fd979d6-wzvjj
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: weave-net-zf59m started at 2021-08-16 22:55:54 +0000
          UTC (0+2 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          weave ready: true, restart count 2\nAug 16 23:39:52.860: INFO: \tContainer
          weave-npc ready: true, restart count 0\nAug 16 23:39:52.860: INFO: prometheus-operator-7f6d8fdc86-l8xxq
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-prometheus-stack ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: registry-5b5c4668f5-bjv6n started
          at 2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: contour-f85dd8bcb-ddvq5 started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: kube-controller-manager-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 23:39:52.900: INFO: \nLatency metrics for node kyle-kurl\nAug 16 23:39:52.900:
          INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP: Destroying
          namespace \"services-3567\" for this suite.\n[AfterEach] [sig-network] Services\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-network] Services should be able to create a functioning NodePort
        service [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:39:52.824: Unexpected error:
              <*errors.errorString | 0xc004b27030>: {
                  s: "out-of-range nodePort (13341) for service",
              }
              out-of-range nodePort (13341) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1237
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:39:52.770: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should be able to create a functioning NodePort service [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating service nodeport-test with type=NodePort in namespace services-3567\nAug
          16 23:39:52.824: FAIL: Unexpected error:\n    <*errors.errorString | 0xc004b27030>:
          {\n        s: \"out-of-range nodePort (13341) for service\",\n    }\n    out-of-range
          nodePort (13341) for service\noccurred\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/network.glob..func24.11()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:1237
          +0x179\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-3567\".\nSTEP: Found 0 events.\nAug
          16 23:39:52.832: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 23:39:52.832:
          INFO: \nAug 16 23:39:52.834: INFO: \nLogging node info for node kyle-kurl\nAug
          16 23:39:52.836: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 32796 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubelet Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>}
          8 DecimalSI},ephemeral-storage: {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi:
          {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:35:04 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:39:52.837: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:39:52.841: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:39:52.860: INFO: kube-apiserver-kyle-kurl started at 2021-08-16 22:08:48
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO:
          \tContainer kube-apiserver ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: envoy-jdqkw started at 2021-08-16 22:56:48 +0000 UTC (1+2 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-osd-0-667b79b95b-v8lll
          started at 2021-08-16 22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container config-init ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tInit container copy-bins ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: \tContainer osd ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5
          started at 2021-08-16 22:55:43 +0000 UTC (1+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started
          at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer contour ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc
          started at 2021-08-16 22:57:18 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer copy-bins ready: false, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer provision ready: false, restart
          count 0\nAug 16 23:39:52.860: INFO: rook-discover-f6bdb started at 2021-08-16
          22:56:06 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-discover ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: grafana-5b868476b6-jkgng started at 2021-08-16 22:55:43 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tInit container
          grafana-sc-datasources ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: \tContainer grafana ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: \tContainer grafana-sc-dashboard ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer mgr ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: prometheus-node-exporter-nnn42 started at 2021-08-16 22:55:57 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 23:39:52.860: INFO: prometheus-k8s-0
          started at 2021-08-16 22:56:36 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:39:52.860: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: alertmanager-prometheus-alertmanager-0 started
          at 2021-08-16 22:56:05 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: rook-ceph-agent-vvbln started at 2021-08-16
          22:58:08 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer kube-proxy ready:
          true, restart count 0\nAug 16 23:39:52.860: INFO: kube-state-metrics-f97897479-rk67g
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: registry-5b5c4668f5-mh2mj started at
          2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16
          23:39:52.860: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: coredns-f9fd979d6-lq9fv started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          started at 2021-08-16 22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: rook-ceph-operator-747c86774c-9b5zf started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16
          23:39:52.860: INFO: prometheus-adapter-75c7788d57-5b8h6 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer prometheus-adapter ready: true, restart count 0\nAug 16
          23:39:52.860: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 16 23:39:52.860:
          INFO: ekc-operator-5888598d79-nc89z started at 2021-08-16 22:55:43 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 23:39:52.860: INFO: coredns-f9fd979d6-wzvjj
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: weave-net-zf59m started at 2021-08-16 22:55:54 +0000
          UTC (0+2 container statuses recorded)\nAug 16 23:39:52.860: INFO: \tContainer
          weave ready: true, restart count 2\nAug 16 23:39:52.860: INFO: \tContainer
          weave-npc ready: true, restart count 0\nAug 16 23:39:52.860: INFO: prometheus-operator-7f6d8fdc86-l8xxq
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer kube-prometheus-stack ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: registry-5b5c4668f5-bjv6n started
          at 2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:39:52.860: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:39:52.860: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:39:52.860: INFO: contour-f85dd8bcb-ddvq5 started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:39:52.860: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 23:39:52.860: INFO: kube-controller-manager-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:39:52.860:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 23:39:52.900: INFO: \nLatency metrics for node kyle-kurl\nAug 16 23:39:52.900:
          INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP: Destroying
          namespace \"services-3567\" for this suite.\n[AfterEach] [sig-network] Services\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-scheduling] SchedulerPreemption [Serial] validates lower priority
        pod preemption by critical pod [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:43:09.328: We need at least two pods to be created butall nodes are already heavily utilized, so preemption tests cannot be run
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:253
        system-out: "[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:42:09.230: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          sched-preemption\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:89\nAug
          16 23:42:09.271: INFO: Waiting up to 1m0s for all nodes to be ready\nAug
          16 23:43:09.310: INFO: Waiting for terminating namespaces to be deleted...\n[It]
          validates lower priority pod preemption by critical pod [Conformance]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          Create pods that use 2/3 of node resources.\nAug 16 23:43:09.327: INFO:
          Created pod: pod0-sched-preemption-low-priority\nAug 16 23:43:09.328: FAIL:
          We need at least two pods to be created butall nodes are already heavily
          utilized, so preemption tests cannot be run\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/scheduling.glob..func5.4()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:253
          +0x101e\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"sched-preemption-3242\".\nSTEP: Found
          0 events.\nAug 16 23:43:09.332: INFO: POD                                 NODE
          \ PHASE    GRACE  CONDITIONS\nAug 16 23:43:09.333: INFO: pod0-sched-preemption-low-priority
          \       Pending         []\nAug 16 23:43:09.333: INFO: \nAug 16 23:43:09.336:
          INFO: \nLogging node info for node kyle-kurl\nAug 16 23:43:09.339: INFO:
          Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl fa8d53a9-9416-47dd-8071-ca25c7b20a51
          35751 0 2021-08-16 22:08:45 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64
          beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl
          kubernetes.io/os:linux kurl.sh/cluster:true node-role.kubernetes.io/master:]
          map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock node.alpha.kubernetes.io/ttl:0
          volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{kubelet
          Update v1 2021-08-16 22:08:45 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}
          {e2e.test Update v1 2021-08-16 23:43:09 +0000 UTC FieldsV1 {\"f:status\":{\"f:capacity\":{\"f:scheduling.k8s.io/foo\":{}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo: {{3 0} {<nil>} 3
          DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage:
          {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi: {{0 0}
          {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:40:05 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:40:05 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:40:05 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:40:05 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:43:09.340: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:43:09.343: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:43:09.367: INFO: coredns-f9fd979d6-wzvjj started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:43:09.367: INFO:
          \tContainer coredns ready: true, restart count 0\nAug 16 23:43:09.367: INFO:
          weave-net-zf59m started at 2021-08-16 22:55:54 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer weave ready:
          true, restart count 2\nAug 16 23:43:09.367: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: ekc-operator-5888598d79-nc89z
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer ekc-operator ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: registry-5b5c4668f5-bjv6n started at 2021-08-16
          22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tInit container restore ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: contour-f85dd8bcb-ddvq5 started at 2021-08-16 22:55:43 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer contour
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: kube-controller-manager-kyle-kurl
          started at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer kube-controller-manager ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: prometheus-operator-7f6d8fdc86-l8xxq
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer kube-prometheus-stack ready: true, restart
          count 0\nAug 16 23:43:09.367: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:43:09.367: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: sonobuoy-e2e-job-587c54c6a51d4b83
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 23:43:09.367: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:43:09.367: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tContainer contour ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: kube-apiserver-kyle-kurl started
          at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: envoy-jdqkw started at 2021-08-16 22:56:48
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:43:09.367: INFO:
          \tInit container envoy-initconfig ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer envoy ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer shutdown-manager ready: true, restart count 0\nAug 16
          23:43:09.367: INFO: rook-ceph-osd-0-667b79b95b-v8lll started at 2021-08-16
          22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tInit container config-init ready: true, restart count 0\nAug 16
          23:43:09.367: INFO: \tInit container copy-bins ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: \tContainer osd ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5 started at
          2021-08-16 22:55:43 +0000 UTC (1+1 container statuses recorded)\nAug 16
          23:43:09.367: INFO: \tInit container init-mon-fs ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: \tContainer mon ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc started
          at 2021-08-16 22:57:18 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer copy-bins ready: false, restart count
          0\nAug 16 23:43:09.367: INFO: \tContainer provision ready: false, restart
          count 0\nAug 16 23:43:09.367: INFO: grafana-5b868476b6-jkgng started at
          2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16
          23:43:09.367: INFO: \tInit container grafana-sc-datasources ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: \tContainer grafana ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: \tContainer grafana-sc-dashboard
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer mgr ready: true, restart count 0\nAug
          16 23:43:09.367: INFO: prometheus-node-exporter-nnn42 started at 2021-08-16
          22:55:57 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tContainer node-exporter ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: rook-discover-f6bdb started at 2021-08-16 22:56:06 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer rook-discover
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: kube-proxy-gpjcf
          started at 2021-08-16 22:08:56 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer kube-proxy ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: prometheus-k8s-0 started at 2021-08-16 22:56:36
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:43:09.367: INFO:
          \tInit container init-config-reloader ready: true, restart count 0\nAug
          16 23:43:09.367: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:43:09.367: INFO: \tContainer prometheus ready: true,
          restart count 0\nAug 16 23:43:09.367: INFO: sonobuoy started at 2021-08-16
          22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tContainer kube-sonobuoy ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: alertmanager-prometheus-alertmanager-0 started at 2021-08-16 22:56:05
          +0000 UTC (0+2 container statuses recorded)\nAug 16 23:43:09.367: INFO:
          \tContainer alertmanager ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer config-reloader ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: rook-ceph-agent-vvbln started at 2021-08-16 22:58:08 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer rook-ceph-agent
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          started at 2021-08-16 22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 23:43:09.367: INFO: kube-state-metrics-f97897479-rk67g started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:43:09.367:
          INFO: \tContainer kube-state-metrics ready: true, restart count 0\nAug 16
          23:43:09.367: INFO: registry-5b5c4668f5-mh2mj started at 2021-08-16 22:55:43
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:43:09.367: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 23:43:09.367:
          INFO: coredns-f9fd979d6-lq9fv started at 2021-08-16 22:55:43 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:43:09.367: INFO: \tContainer coredns
          ready: true, restart count 0\nAug 16 23:43:09.367: INFO: prometheus-adapter-75c7788d57-5b8h6
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer prometheus-adapter ready: true, restart
          count 0\nAug 16 23:43:09.367: INFO: kube-scheduler-kyle-kurl started at
          2021-08-16 22:08:49 +0000 UTC (0+1 container statuses recorded)\nAug 16
          23:43:09.367: INFO: \tContainer kube-scheduler ready: true, restart count
          0\nAug 16 23:43:09.367: INFO: rook-ceph-operator-747c86774c-9b5zf started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:43:09.367: INFO: \tContainer rook-ceph-operator ready: true, restart
          count 0\nAug 16 23:43:09.396: INFO: \nLatency metrics for node kyle-kurl\nAug
          16 23:43:09.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP:
          Destroying namespace \"sched-preemption-3242\" for this suite.\n[AfterEach]
          [sig-scheduling] SchedulerPreemption [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:77\n"
    - name: '[sig-network] Services should have session affinity timeout work for
        NodePort service [LinuxOnly] [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:45:40.631: Unexpected error:
              <*errors.errorString | 0xc00399f7d0>: {
                  s: "out-of-range nodePort (33221) for service",
              }
              out-of-range nodePort (33221) for service
          occurred
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3444
        system-out: "[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:45:29.292: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          services\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:782\n[It]
          should have session affinity timeout work for NodePort service [LinuxOnly]
          [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          creating service in namespace services-6568\nAug 16 23:45:31.332: INFO:
          Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-789370980 --namespace=services-6568
          exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout
          1 http://localhost:10249/proxyMode'\nAug 16 23:45:31.539: INFO: stderr:
          \"+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\\n\"\nAug
          16 23:45:31.539: INFO: stdout: \"ipvs\"\nAug 16 23:45:31.539: INFO: proxyMode:
          ipvs\nAug 16 23:45:31.543: INFO: Waiting for pod kube-proxy-mode-detector
          to disappear\nAug 16 23:45:31.547: INFO: Pod kube-proxy-mode-detector still
          exists\nAug 16 23:45:33.547: INFO: Waiting for pod kube-proxy-mode-detector
          to disappear\nAug 16 23:45:33.550: INFO: Pod kube-proxy-mode-detector still
          exists\nAug 16 23:45:35.547: INFO: Waiting for pod kube-proxy-mode-detector
          to disappear\nAug 16 23:45:35.550: INFO: Pod kube-proxy-mode-detector no
          longer exists\nSTEP: creating service affinity-nodeport-timeout in namespace
          services-6568\nSTEP: creating replication controller affinity-nodeport-timeout
          in namespace services-6568\nAug 16 23:45:38.621: INFO: Creating new exec
          pod\nAug 16 23:45:40.631: FAIL: Unexpected error:\n    <*errors.errorString
          | 0xc00399f7d0>: {\n        s: \"out-of-range nodePort (33221) for service\",\n
          \   }\n    out-of-range nodePort (33221) for service\noccurred\n\nFull Stack
          Trace\nk8s.io/kubernetes/test/e2e/network.execAffinityTestForSessionAffinityTimeout(0xc000bb2b00,
          0x5411460, 0xc002267760, 0xc0003ad200)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:3444
          +0x751\nk8s.io/kubernetes/test/e2e/network.glob..func24.29()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:2525
          +0x9c\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\nAug 16 23:45:40.631: INFO: Cleaning up the exec pod\nSTEP: deleting
          ReplicationController affinity-nodeport-timeout in namespace services-6568,
          will wait for the garbage collector to delete the pods\nAug 16 23:45:40.701:
          INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.509845ms\nAug
          16 23:45:41.501: INFO: Terminating ReplicationController affinity-nodeport-timeout
          pods took: 800.377573ms\n[AfterEach] [sig-network] Services\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"services-6568\".\nSTEP: Found 28 events.\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:29 +0000 UTC - event for kube-proxy-mode-detector:
          {kubelet kyle-kurl} Created: Created container detector\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:29 +0000 UTC - event for kube-proxy-mode-detector:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:29
          +0000 UTC - event for kube-proxy-mode-detector: {default-scheduler } Scheduled:
          Successfully assigned services-6568/kube-proxy-mode-detector to kyle-kurl\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:30 +0000 UTC - event for kube-proxy-mode-detector:
          {kubelet kyle-kurl} Started: Started container detector\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:32 +0000 UTC - event for kube-proxy-mode-detector:
          {kubelet kyle-kurl} Killing: Stopping container detector\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:35 +0000 UTC - event for affinity-nodeport-timeout:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-timeout-4rstk\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:35 +0000 UTC - event for affinity-nodeport-timeout:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-timeout-z6w5h\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:35 +0000 UTC - event for affinity-nodeport-timeout:
          {replication-controller } SuccessfulCreate: Created pod: affinity-nodeport-timeout-r5gdn\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:35 +0000 UTC - event for affinity-nodeport-timeout-4rstk:
          {default-scheduler } Scheduled: Successfully assigned services-6568/affinity-nodeport-timeout-4rstk
          to kyle-kurl\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:35 +0000 UTC
          - event for affinity-nodeport-timeout-r5gdn: {default-scheduler } Scheduled:
          Successfully assigned services-6568/affinity-nodeport-timeout-r5gdn to kyle-kurl\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:35 +0000 UTC - event for affinity-nodeport-timeout-z6w5h:
          {default-scheduler } Scheduled: Successfully assigned services-6568/affinity-nodeport-timeout-z6w5h
          to kyle-kurl\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:36 +0000 UTC
          - event for affinity-nodeport-timeout-4rstk: {kubelet kyle-kurl} Started:
          Started container affinity-nodeport-timeout\nAug 16 23:45:58.128: INFO:
          At 2021-08-16 23:45:36 +0000 UTC - event for affinity-nodeport-timeout-4rstk:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:36
          +0000 UTC - event for affinity-nodeport-timeout-4rstk: {kubelet kyle-kurl}
          Created: Created container affinity-nodeport-timeout\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:36 +0000 UTC - event for affinity-nodeport-timeout-r5gdn:
          {kubelet kyle-kurl} Started: Started container affinity-nodeport-timeout\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:36 +0000 UTC - event for affinity-nodeport-timeout-r5gdn:
          {kubelet kyle-kurl} Created: Created container affinity-nodeport-timeout\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:36 +0000 UTC - event for affinity-nodeport-timeout-r5gdn:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:37
          +0000 UTC - event for affinity-nodeport-timeout-z6w5h: {kubelet kyle-kurl}
          Created: Created container affinity-nodeport-timeout\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:37 +0000 UTC - event for affinity-nodeport-timeout-z6w5h:
          {kubelet kyle-kurl} Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\"
          already present on machine\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:37
          +0000 UTC - event for affinity-nodeport-timeout-z6w5h: {kubelet kyle-kurl}
          Started: Started container affinity-nodeport-timeout\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:38 +0000 UTC - event for execpod-affinity7vrm9:
          {default-scheduler } Scheduled: Successfully assigned services-6568/execpod-affinity7vrm9
          to kyle-kurl\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:39 +0000 UTC
          - event for execpod-affinity7vrm9: {kubelet kyle-kurl} Created: Created
          container agnhost-container\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:39
          +0000 UTC - event for execpod-affinity7vrm9: {kubelet kyle-kurl} Started:
          Started container agnhost-container\nAug 16 23:45:58.128: INFO: At 2021-08-16
          23:45:39 +0000 UTC - event for execpod-affinity7vrm9: {kubelet kyle-kurl}
          Pulled: Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.20\" already
          present on machine\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:40 +0000
          UTC - event for execpod-affinity7vrm9: {kubelet kyle-kurl} Killing: Stopping
          container agnhost-container\nAug 16 23:45:58.128: INFO: At 2021-08-16 23:45:41
          +0000 UTC - event for affinity-nodeport-timeout-4rstk: {kubelet kyle-kurl}
          Killing: Stopping container affinity-nodeport-timeout\nAug 16 23:45:58.128:
          INFO: At 2021-08-16 23:45:41 +0000 UTC - event for affinity-nodeport-timeout-r5gdn:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport-timeout\nAug
          16 23:45:58.128: INFO: At 2021-08-16 23:45:41 +0000 UTC - event for affinity-nodeport-timeout-z6w5h:
          {kubelet kyle-kurl} Killing: Stopping container affinity-nodeport-timeout\nAug
          16 23:45:58.131: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 23:45:58.131:
          INFO: \nAug 16 23:45:58.133: INFO: \nLogging node info for node kyle-kurl\nAug
          16 23:45:58.136: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 35863 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}
          {e2e.test Update v1 2021-08-16 23:43:09 +0000 UTC FieldsV1 {\"f:status\":{\"f:capacity\":{\"f:scheduling.k8s.io/foo\":{}}}}}
          {kubelet Update v1 2021-08-16 23:43:15 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{},\"f:scheduling.k8s.io/foo\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo: {{3 0} {<nil>} 3
          DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage:
          {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi: {{0 0}
          {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo:
          {{3 0} {<nil>} 3 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:43:15 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:43:15 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:43:15 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:43:15 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:45:58.136: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:45:58.140: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:45:58.161: INFO: prometheus-adapter-75c7788d57-5b8h6 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer prometheus-adapter ready: true, restart count 0\nAug 16
          23:45:58.161: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: rook-ceph-operator-747c86774c-9b5zf started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: ekc-operator-5888598d79-nc89z started at 2021-08-16 22:55:43 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161: INFO: \tContainer
          ekc-operator ready: true, restart count 0\nAug 16 23:45:58.161: INFO: coredns-f9fd979d6-wzvjj
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: weave-net-zf59m started at 2021-08-16 22:55:54 +0000
          UTC (0+2 container statuses recorded)\nAug 16 23:45:58.161: INFO: \tContainer
          weave ready: true, restart count 2\nAug 16 23:45:58.161: INFO: \tContainer
          weave-npc ready: true, restart count 0\nAug 16 23:45:58.161: INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d
          started at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:45:58.161: INFO: \tContainer systemd-logs ready: true,
          restart count 0\nAug 16 23:45:58.161: INFO: registry-5b5c4668f5-bjv6n started
          at 2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:45:58.161: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:45:58.161: INFO: contour-f85dd8bcb-ddvq5 started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: kube-controller-manager-kyle-kurl started at 2021-08-16
          22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: prometheus-operator-7f6d8fdc86-l8xxq started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer kube-prometheus-stack ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: rook-ceph-osd-0-667b79b95b-v8lll started at 2021-08-16
          22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tInit container config-init ready: true, restart count 0\nAug 16
          23:45:58.161: INFO: \tInit container copy-bins ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: \tContainer osd ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5 started at
          2021-08-16 22:55:43 +0000 UTC (1+1 container statuses recorded)\nAug 16
          23:45:58.161: INFO: \tInit container init-mon-fs ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: \tContainer mon ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started
          at 2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer e2e ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:45:58.161: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer contour ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:45:58.161: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 16 23:45:58.161: INFO: kube-apiserver-kyle-kurl started
          at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: envoy-jdqkw started at 2021-08-16 22:56:48
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:45:58.161: INFO:
          \tInit container envoy-initconfig ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: \tContainer envoy ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: \tContainer shutdown-manager ready: true, restart count 0\nAug 16
          23:45:58.161: INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc started at 2021-08-16
          22:57:18 +0000 UTC (0+2 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer copy-bins ready: false, restart count 0\nAug 16 23:45:58.161:
          INFO: \tContainer provision ready: false, restart count 0\nAug 16 23:45:58.161:
          INFO: grafana-5b868476b6-jkgng started at 2021-08-16 22:55:43 +0000 UTC
          (1+2 container statuses recorded)\nAug 16 23:45:58.161: INFO: \tInit container
          grafana-sc-datasources ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: \tContainer grafana ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: \tContainer grafana-sc-dashboard ready: true, restart count 0\nAug
          16 23:45:58.161: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8 started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer mgr ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: prometheus-node-exporter-nnn42 started at 2021-08-16 22:55:57 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161: INFO: \tContainer
          node-exporter ready: true, restart count 0\nAug 16 23:45:58.161: INFO: rook-discover-f6bdb
          started at 2021-08-16 22:56:06 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: alertmanager-prometheus-alertmanager-0 started
          at 2021-08-16 22:56:05 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 23:45:58.161: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:45:58.161: INFO: rook-ceph-agent-vvbln started at 2021-08-16
          22:58:08 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.161:
          INFO: \tContainer rook-ceph-agent ready: true, restart count 0\nAug 16 23:45:58.161:
          INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:45:58.161: INFO: \tContainer kube-proxy ready:
          true, restart count 0\nAug 16 23:45:58.161: INFO: prometheus-k8s-0 started
          at 2021-08-16 22:56:36 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:45:58.161: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 23:45:58.161: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:45:58.161: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:45:58.161: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.162: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 23:45:58.162: INFO: registry-5b5c4668f5-mh2mj started at 2021-08-16
          22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16 23:45:58.162:
          INFO: \tInit container restore ready: true, restart count 0\nAug 16 23:45:58.162:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 23:45:58.162:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 23:45:58.162:
          INFO: coredns-f9fd979d6-lq9fv started at 2021-08-16 22:55:43 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:45:58.162: INFO: \tContainer coredns
          ready: true, restart count 0\nAug 16 23:45:58.162: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          started at 2021-08-16 22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:45:58.162: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 23:45:58.162: INFO: kube-state-metrics-f97897479-rk67g started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:45:58.162:
          INFO: \tContainer kube-state-metrics ready: true, restart count 0\nAug 16
          23:45:58.210: INFO: \nLatency metrics for node kyle-kurl\nAug 16 23:45:58.210:
          INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP: Destroying
          namespace \"services-6568\" for this suite.\n[AfterEach] [sig-network] Services\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:786\n"
    - name: '[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector
        is respected if not matching  [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 16 23:56:20.628: Timed out after 10m0s waiting for stable cluster.
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:55
        system-out: "[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 16 23:46:20.579: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          sched-pred\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90\nAug
          16 23:46:20.603: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready\nAug
          16 23:46:20.609: INFO: Waiting for terminating namespaces to be deleted...\nAug
          16 23:46:20.611: INFO: \nLogging pods the apiserver thinks is on node kyle-kurl
          before test\nAug 16 23:46:20.623: INFO: client-containers-f51b064c-dd01-4338-8a30-cdac294b5c55
          from containers-2566 started at 2021-08-16 23:46:10 +0000 UTC (1 container
          statuses recorded)\nAug 16 23:46:20.623: INFO: \tContainer test-container
          ready: true, restart count 0\nAug 16 23:46:20.623: INFO: coredns-f9fd979d6-lq9fv
          from kube-system started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.623: INFO: \tContainer coredns ready: true, restart
          count 0\nAug 16 23:46:20.623: INFO: coredns-f9fd979d6-wzvjj from kube-system
          started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses recorded)\nAug
          16 23:46:20.623: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:46:20.623: INFO: etcd-kyle-kurl from kube-system started at 2021-08-16
          22:08:48 +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.623:
          INFO: \tContainer etcd ready: true, restart count 0\nAug 16 23:46:20.623:
          INFO: kube-apiserver-kyle-kurl from kube-system started at 2021-08-16 22:08:48
          +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.623: INFO: \tContainer
          kube-apiserver ready: true, restart count 0\nAug 16 23:46:20.623: INFO:
          kube-controller-manager-kyle-kurl from kube-system started at 2021-08-16
          22:08:48 +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.623:
          INFO: \tContainer kube-controller-manager ready: true, restart count 0\nAug
          16 23:46:20.623: INFO: kube-proxy-gpjcf from kube-system started at 2021-08-16
          22:08:56 +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.623:
          INFO: \tContainer kube-proxy ready: true, restart count 0\nAug 16 23:46:20.623:
          INFO: kube-scheduler-kyle-kurl from kube-system started at 2021-08-16 22:08:49
          +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.623: INFO: \tContainer
          kube-scheduler ready: true, restart count 0\nAug 16 23:46:20.623: INFO:
          weave-net-zf59m from kube-system started at 2021-08-16 22:55:54 +0000 UTC
          (2 container statuses recorded)\nAug 16 23:46:20.623: INFO: \tContainer
          weave ready: true, restart count 2\nAug 16 23:46:20.624: INFO: \tContainer
          weave-npc ready: true, restart count 0\nAug 16 23:46:20.624: INFO: ekc-operator-5888598d79-nc89z
          from kurl started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer ekc-operator ready: true,
          restart count 0\nAug 16 23:46:20.624: INFO: registry-5b5c4668f5-bjv6n from
          kurl started at 2021-08-16 22:55:43 +0000 UTC (2 container statuses recorded)\nAug
          16 23:46:20.624: INFO: \tContainer registry ready: true, restart count 0\nAug
          16 23:46:20.624: INFO: \tContainer registry-backup ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: registry-5b5c4668f5-mh2mj from kurl
          started at 2021-08-16 22:55:43 +0000 UTC (2 container statuses recorded)\nAug
          16 23:46:20.624: INFO: \tContainer registry ready: true, restart count 0\nAug
          16 23:46:20.624: INFO: \tContainer registry-backup ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: alertmanager-prometheus-alertmanager-0
          from monitoring started at 2021-08-16 22:56:05 +0000 UTC (2 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer alertmanager ready: true,
          restart count 0\nAug 16 23:46:20.624: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:46:20.624: INFO: grafana-5b868476b6-jkgng
          from monitoring started at 2021-08-16 22:55:43 +0000 UTC (2 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer grafana ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: \tContainer grafana-sc-dashboard ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: kube-state-metrics-f97897479-rk67g
          from monitoring started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer kube-state-metrics ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: prometheus-adapter-75c7788d57-5b8h6
          from monitoring started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer prometheus-adapter ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: prometheus-k8s-0 from
          monitoring started at 2021-08-16 22:56:36 +0000 UTC (2 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer config-reloader ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:46:20.624: INFO: prometheus-node-exporter-nnn42
          from monitoring started at 2021-08-16 22:55:57 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer node-exporter ready: true,
          restart count 0\nAug 16 23:46:20.624: INFO: prometheus-operator-7f6d8fdc86-l8xxq
          from monitoring started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer kube-prometheus-stack
          ready: true, restart count 0\nAug 16 23:46:20.624: INFO: contour-f85dd8bcb-4wjhr
          from projectcontour started at 2021-08-16 22:55:43 +0000 UTC (1 container
          statuses recorded)\nAug 16 23:46:20.624: INFO: \tContainer contour ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: contour-f85dd8bcb-ddvq5
          from projectcontour started at 2021-08-16 22:55:43 +0000 UTC (1 container
          statuses recorded)\nAug 16 23:46:20.624: INFO: \tContainer contour ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: envoy-jdqkw from projectcontour
          started at 2021-08-16 22:56:48 +0000 UTC (2 container statuses recorded)\nAug
          16 23:46:20.624: INFO: \tContainer envoy ready: true, restart count 0\nAug
          16 23:46:20.624: INFO: \tContainer shutdown-manager ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-ceph-agent-vvbln from rook-ceph
          started at 2021-08-16 22:58:08 +0000 UTC (1 container statuses recorded)\nAug
          16 23:46:20.624: INFO: \tContainer rook-ceph-agent ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8 from
          rook-ceph started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer mgr ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5 from
          rook-ceph started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer mon ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-ceph-operator-747c86774c-9b5zf
          from rook-ceph started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer rook-ceph-operator ready:
          true, restart count 0\nAug 16 23:46:20.624: INFO: rook-ceph-osd-0-667b79b95b-v8lll
          from rook-ceph started at 2021-08-16 22:55:43 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer osd ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-ceph-osd-prepare-kyle-kurl-lt6bc
          from rook-ceph started at 2021-08-16 22:57:18 +0000 UTC (2 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer copy-bins ready: false,
          restart count 0\nAug 16 23:46:20.624: INFO: \tContainer provision ready:
          false, restart count 0\nAug 16 23:46:20.624: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          from rook-ceph started at 2021-08-16 22:57:36 +0000 UTC (1 container statuses
          recorded)\nAug 16 23:46:20.624: INFO: \tContainer rgw ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: rook-discover-f6bdb from rook-ceph started
          at 2021-08-16 22:56:06 +0000 UTC (1 container statuses recorded)\nAug 16
          23:46:20.624: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 16 23:46:20.624: INFO: sonobuoy from sonobuoy started at 2021-08-16
          22:12:42 +0000 UTC (1 container statuses recorded)\nAug 16 23:46:20.624:
          INFO: \tContainer kube-sonobuoy ready: true, restart count 0\nAug 16 23:46:20.624:
          INFO: sonobuoy-e2e-job-587c54c6a51d4b83 from sonobuoy started at 2021-08-16
          22:12:46 +0000 UTC (2 container statuses recorded)\nAug 16 23:46:20.624:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 16 23:46:20.624:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 16 23:46:20.624:
          INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d from sonobuoy
          started at 2021-08-16 22:12:46 +0000 UTC (2 container statuses recorded)\nAug
          16 23:46:20.624: INFO: \tContainer sonobuoy-worker ready: true, restart
          count 0\nAug 16 23:46:20.624: INFO: \tContainer systemd-logs ready: true,
          restart count 0\n[It] validates that NodeSelector is respected if not matching
          \ [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          Trying to schedule Pod with nonempty NodeSelector.\nAug 16 23:56:20.628:
          INFO: Timed out waiting for the following pods to schedule\nAug 16 23:56:20.628:
          INFO: monitoring/alertmanager-prometheus-alertmanager-1\nAug 16 23:56:20.628:
          INFO: monitoring/alertmanager-prometheus-alertmanager-2\nAug 16 23:56:20.628:
          INFO: monitoring/prometheus-k8s-1\nAug 16 23:56:20.628: FAIL: Timed out
          after 10m0s waiting for stable cluster.\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/scheduling.WaitForStableCluster(0x5411460,
          0xc0030598c0, 0xc0008b78c0, 0x0)\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:55
          +0x405\nk8s.io/kubernetes/test/e2e/scheduling.glob..func4.6()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:436
          +0xae\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"sched-pred-1415\".\nSTEP: Found 0 events.\nAug
          16 23:56:20.634: INFO: POD  NODE  PHASE  GRACE  CONDITIONS\nAug 16 23:56:20.634:
          INFO: \nAug 16 23:56:20.636: INFO: \nLogging node info for node kyle-kurl\nAug
          16 23:56:20.639: INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl
          fa8d53a9-9416-47dd-8071-ca25c7b20a51 39261 0 2021-08-16 22:08:45 +0000 UTC
          <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux
          kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl kubernetes.io/os:linux
          kurl.sh/cluster:true node-role.kubernetes.io/master:] map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock
          node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true]
          [] []  [{kubeadm Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}
          {e2e.test Update v1 2021-08-16 23:43:09 +0000 UTC FieldsV1 {\"f:status\":{\"f:capacity\":{\"f:scheduling.k8s.io/foo\":{}}}}}
          {kubelet Update v1 2021-08-16 23:43:15 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{},\"f:scheduling.k8s.io/foo\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo: {{3 0} {<nil>} 3
          DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage:
          {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi: {{0 0}
          {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo:
          {{3 0} {<nil>} 3 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          22:56:21 +0000 UTC,LastTransitionTime:2021-08-16 22:56:21 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:53:17 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:53:17 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:53:17 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:53:17 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          16 23:56:20.639: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          16 23:56:20.642: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          16 23:56:20.666: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: rook-ceph-operator-747c86774c-9b5zf started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: kube-controller-manager-kyle-kurl started at 2021-08-16 22:08:48 +0000
          UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer
          kube-controller-manager ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: prometheus-operator-7f6d8fdc86-l8xxq started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tContainer kube-prometheus-stack ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: rook-ceph-mon-a-6f9b75dbb9-dd9z5 started at 2021-08-16 22:55:43 +0000
          UTC (1+1 container statuses recorded)\nAug 16 23:56:20.666: INFO: \tInit
          container init-mon-fs ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: \tContainer mon ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started at 2021-08-16 22:12:46 +0000
          UTC (0+2 container statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer
          e2e ready: true, restart count 0\nAug 16 23:56:20.666: INFO: \tContainer
          sonobuoy-worker ready: true, restart count 0\nAug 16 23:56:20.666: INFO:
          etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses
          recorded)\nAug 16 23:56:20.666: INFO: \tContainer etcd ready: true, restart
          count 0\nAug 16 23:56:20.666: INFO: kube-apiserver-kyle-kurl started at
          2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug 16
          23:56:20.666: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: rook-ceph-osd-0-667b79b95b-v8lll started at
          2021-08-16 22:55:43 +0000 UTC (2+1 container statuses recorded)\nAug 16
          23:56:20.666: INFO: \tInit container config-init ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: \tInit container copy-bins ready: true, restart
          count 0\nAug 16 23:56:20.666: INFO: \tContainer osd ready: true, restart
          count 0\nAug 16 23:56:20.666: INFO: rook-discover-f6bdb started at 2021-08-16
          22:56:06 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666:
          INFO: \tContainer rook-discover ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000 UTC (0+1 container
          statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer kube-proxy ready:
          true, restart count 0\nAug 16 23:56:20.666: INFO: coredns-f9fd979d6-lq9fv
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer coredns ready: true, restart count 0\nAug
          16 23:56:20.666: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-knrwb
          started at 2021-08-16 22:57:36 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer rgw ready: true, restart count 0\nAug
          16 23:56:20.666: INFO: kube-state-metrics-f97897479-rk67g started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666:
          INFO: \tContainer kube-state-metrics ready: true, restart count 0\nAug 16
          23:56:20.666: INFO: registry-5b5c4668f5-mh2mj started at 2021-08-16 22:55:43
          +0000 UTC (1+2 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tInit container restore ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: \tContainer registry ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: prometheus-adapter-75c7788d57-5b8h6 started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tContainer prometheus-adapter ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: weave-net-zf59m started at 2021-08-16 22:55:54 +0000 UTC (0+2 container
          statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer weave ready:
          true, restart count 2\nAug 16 23:56:20.666: INFO: \tContainer weave-npc
          ready: true, restart count 0\nAug 16 23:56:20.666: INFO: ekc-operator-5888598d79-nc89z
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer ekc-operator ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: coredns-f9fd979d6-wzvjj started at 2021-08-16
          22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d started at
          2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 16
          23:56:20.666: INFO: \tContainer sonobuoy-worker ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: \tContainer systemd-logs ready: true, restart
          count 0\nAug 16 23:56:20.666: INFO: registry-5b5c4668f5-bjv6n started at
          2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug 16
          23:56:20.666: INFO: \tInit container restore ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: \tContainer registry ready: true, restart
          count 0\nAug 16 23:56:20.666: INFO: \tContainer registry-backup ready: true,
          restart count 0\nAug 16 23:56:20.666: INFO: contour-f85dd8bcb-ddvq5 started
          at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer contour ready: true, restart count 0\nAug
          16 23:56:20.666: INFO: envoy-jdqkw started at 2021-08-16 22:56:48 +0000
          UTC (1+2 container statuses recorded)\nAug 16 23:56:20.666: INFO: \tInit
          container envoy-initconfig ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: \tContainer envoy ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: \tContainer shutdown-manager ready: true, restart count 0\nAug 16
          23:56:20.666: INFO: contour-f85dd8bcb-4wjhr started at 2021-08-16 22:55:43
          +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666: INFO:
          \tContainer contour ready: true, restart count 0\nAug 16 23:56:20.666: INFO:
          rook-ceph-osd-prepare-kyle-kurl-lt6bc started at 2021-08-16 22:57:18 +0000
          UTC (0+2 container statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer
          copy-bins ready: false, restart count 0\nAug 16 23:56:20.666: INFO: \tContainer
          provision ready: false, restart count 0\nAug 16 23:56:20.666: INFO: grafana-5b868476b6-jkgng
          started at 2021-08-16 22:55:43 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tInit container grafana-sc-datasources ready: true,
          restart count 0\nAug 16 23:56:20.666: INFO: \tContainer grafana ready: true,
          restart count 0\nAug 16 23:56:20.666: INFO: \tContainer grafana-sc-dashboard
          ready: true, restart count 0\nAug 16 23:56:20.666: INFO: rook-ceph-mgr-a-7c8fb8db97-458c8
          started at 2021-08-16 22:55:43 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer mgr ready: true, restart count 0\nAug
          16 23:56:20.666: INFO: prometheus-node-exporter-nnn42 started at 2021-08-16
          22:55:57 +0000 UTC (0+1 container statuses recorded)\nAug 16 23:56:20.666:
          INFO: \tContainer node-exporter ready: true, restart count 0\nAug 16 23:56:20.666:
          INFO: rook-ceph-agent-vvbln started at 2021-08-16 22:58:08 +0000 UTC (0+1
          container statuses recorded)\nAug 16 23:56:20.666: INFO: \tContainer rook-ceph-agent
          ready: true, restart count 0\nAug 16 23:56:20.666: INFO: prometheus-k8s-0
          started at 2021-08-16 22:56:36 +0000 UTC (1+2 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tInit container init-config-reloader ready: true,
          restart count 0\nAug 16 23:56:20.666: INFO: \tContainer config-reloader
          ready: true, restart count 0\nAug 16 23:56:20.666: INFO: \tContainer prometheus
          ready: true, restart count 0\nAug 16 23:56:20.666: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: alertmanager-prometheus-alertmanager-0 started
          at 2021-08-16 22:56:05 +0000 UTC (0+2 container statuses recorded)\nAug
          16 23:56:20.666: INFO: \tContainer alertmanager ready: true, restart count
          0\nAug 16 23:56:20.666: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 16 23:56:20.694: INFO: \nLatency metrics for node kyle-kurl\nAug
          16 23:56:20.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready\nSTEP:
          Destroying namespace \"sched-pred-1415\" for this suite.\n[AfterEach] [sig-scheduling]
          SchedulerPredicates [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81\n"
    - name: '[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption
        works [Conformance]'
      status: failed
      details:
        failure: |-
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597
          Aug 17 00:01:46.145: We need at least two pods to be created butall nodes are already heavily utilized, so preemption tests cannot be run
          /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:167
        system-out: "[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:174\nSTEP:
          Creating a kubernetes client\nAug 17 00:00:46.047: INFO: >>> kubeConfig:
          /tmp/kubeconfig-789370980\nSTEP: Building a namespace api object, basename
          sched-preemption\nSTEP: Waiting for a default service account to be provisioned
          in namespace\n[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]\n
          \ /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:89\nAug
          17 00:00:46.092: INFO: Waiting up to 1m0s for all nodes to be ready\nAug
          17 00:01:46.129: INFO: Waiting for terminating namespaces to be deleted...\n[It]
          validates basic preemption works [Conformance]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:597\nSTEP:
          Create pods that use 2/3 of node resources.\nAug 17 00:01:46.145: INFO:
          Created pod: pod0-sched-preemption-low-priority\nAug 17 00:01:46.145: FAIL:
          We need at least two pods to be created butall nodes are already heavily
          utilized, so preemption tests cannot be run\n\nFull Stack Trace\nk8s.io/kubernetes/test/e2e/scheduling.glob..func5.3()\n\t/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:167
          +0xf86\nk8s.io/kubernetes/test/e2e.RunE2ETests(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130
          +0x345\nk8s.io/kubernetes/test/e2e.TestE2E(0xc000bfa600)\n\t_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:145
          +0x2b\ntesting.tRunner(0xc000bfa600, 0x4dec418)\n\t/usr/local/go/src/testing/testing.go:1123
          +0xef\ncreated by testing.(*T).Run\n\t/usr/local/go/src/testing/testing.go:1168
          +0x2b3\n[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:175\nSTEP:
          Collecting events from namespace \"sched-preemption-7608\".\nSTEP: Found
          0 events.\nAug 17 00:01:46.152: INFO: POD                                 NODE
          \      PHASE    GRACE  CONDITIONS\nAug 17 00:01:46.152: INFO: pod0-sched-preemption-low-priority
          \ kyle-kurl  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000
          UTC 2021-08-17 00:01:46 +0000 UTC  }]\nAug 17 00:01:46.152: INFO: \nAug
          17 00:01:46.154: INFO: \nLogging node info for node kyle-kurl\nAug 17 00:01:46.156:
          INFO: Node Info: &Node{ObjectMeta:{kyle-kurl   /api/v1/nodes/kyle-kurl fa8d53a9-9416-47dd-8071-ca25c7b20a51
          41706 0 2021-08-16 22:08:45 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64
          beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:kyle-kurl
          kubernetes.io/os:linux kurl.sh/cluster:true node-role.kubernetes.io/master:]
          map[kubeadm.alpha.kubernetes.io/cri-socket:/var/run/dockershim.sock node.alpha.kubernetes.io/ttl:0
          volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{kubeadm
          Update v1 2021-08-16 22:08:47 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\"f:kubeadm.alpha.kubernetes.io/cri-socket\":{}},\"f:labels\":{\"f:node-role.kubernetes.io/master\":{}}}}}
          {kube-controller-manager Update v1 2021-08-16 22:08:56 +0000 UTC FieldsV1
          {\"f:metadata\":{\"f:annotations\":{\"f:node.alpha.kubernetes.io/ttl\":{}}}}}
          {kube-utils Update v1 2021-08-16 22:09:06 +0000 UTC FieldsV1 {\"f:status\":{\"f:conditions\":{\"k:{\\\"type\\\":\\\"NetworkUnavailable\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}}}}}
          {kubelet Update v1 2021-08-16 23:43:15 +0000 UTC FieldsV1 {\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:volumes.kubernetes.io/controller-managed-attach-detach\":{}},\"f:labels\":{\".\":{},\"f:beta.kubernetes.io/arch\":{},\"f:beta.kubernetes.io/os\":{},\"f:kubernetes.io/arch\":{},\"f:kubernetes.io/hostname\":{},\"f:kubernetes.io/os\":{},\"f:kurl.sh/cluster\":{}}},\"f:status\":{\"f:addresses\":{\".\":{},\"k:{\\\"type\\\":\\\"Hostname\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"InternalIP\\\"}\":{\".\":{},\"f:address\":{},\"f:type\":{}}},\"f:allocatable\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{},\"f:scheduling.k8s.io/foo\":{}},\"f:capacity\":{\".\":{},\"f:cpu\":{},\"f:ephemeral-storage\":{},\"f:hugepages-1Gi\":{},\"f:hugepages-2Mi\":{},\"f:memory\":{},\"f:pods\":{}},\"f:conditions\":{\".\":{},\"k:{\\\"type\\\":\\\"DiskPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"MemoryPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"PIDPressure\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}},\"k:{\\\"type\\\":\\\"Ready\\\"}\":{\".\":{},\"f:lastHeartbeatTime\":{},\"f:lastTransitionTime\":{},\"f:message\":{},\"f:reason\":{},\"f:status\":{},\"f:type\":{}}},\"f:daemonEndpoints\":{\"f:kubeletEndpoint\":{\"f:Port\":{}}},\"f:images\":{},\"f:nodeInfo\":{\"f:architecture\":{},\"f:bootID\":{},\"f:containerRuntimeVersion\":{},\"f:kernelVersion\":{},\"f:kubeProxyVersion\":{},\"f:kubeletVersion\":{},\"f:machineID\":{},\"f:operatingSystem\":{},\"f:osImage\":{},\"f:systemUUID\":{}}}}}
          {e2e.test Update v1 2021-08-16 23:57:25 +0000 UTC FieldsV1 {\"f:status\":{\"f:capacity\":{\"f:scheduling.k8s.io/foo\":{}}}}}]},Spec:NodeSpec{PodCIDR:,DoNotUseExternalID:,ProviderID:,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[],},Status:NodeStatus{Capacity:ResourceList{cpu:
          {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{207944110080 0} {<nil>}
          203070420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi:
          {{0 0} {<nil>} 0 DecimalSI},memory: {{31559720960 0} {<nil>}  BinarySI},pods:
          {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo: {{3 0} {<nil>} 3
          DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage:
          {{187149698763 0} {<nil>} 187149698763 DecimalSI},hugepages-1Gi: {{0 0}
          {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory:
          {{31454863360 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},scheduling.k8s.io/foo:
          {{3 0} {<nil>} 3 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2021-08-16
          23:58:01 +0000 UTC,LastTransitionTime:2021-08-16 23:58:01 +0000 UTC,Reason:WeaveIsUp,Message:Weave
          pod has set this,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:58:58 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet
          has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:58:58 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet
          has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2021-08-16
          23:58:58 +0000 UTC,LastTransitionTime:2021-08-16 22:08:45 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet
          has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2021-08-16
          23:58:58 +0000 UTC,LastTransitionTime:2021-08-16 22:09:08 +0000 UTC,Reason:KubeletReady,Message:kubelet
          is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:10.128.0.106,},NodeAddress{Type:Hostname,Address:kyle-kurl,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:dde4f72d12ec689ffd58175f059f1e64,SystemUUID:dde4f72d-12ec-689f-fd58-175f059f1e64,BootID:04534816-4322-44be-b5ac-422cf38fd56b,KernelVersion:5.4.0-1049-gcp,OSImage:Ubuntu
          18.04.5 LTS,ContainerRuntimeVersion:docker://20.10.5,KubeletVersion:v1.19.13,KubeProxyVersion:v1.19.13,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[kurlsh/rook-ceph:v1.0.4-9065b09-20210625],SizeBytes:1028152912,},ContainerImage{Names:[kurlsh/ceph:v14.2.0-9065b09-20210625],SizeBytes:957692166,},ContainerImage{Names:[replicated/kurl-util:v2021.08.16-0],SizeBytes:387837491,},ContainerImage{Names:[sonobuoy/systemd-logs@sha256:fadad24a66ddd544987c38811108a73d1a306dd3b5e3f090b207786f2825ffde
          sonobuoy/systemd-logs:v0.3],SizeBytes:297365055,},ContainerImage{Names:[k8s.gcr.io/etcd:3.4.13-0],SizeBytes:253392289,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:5bd78ea82827d11a886a74c4d72a8a9a80c826e0181610a1f1bb2bbf74d581ae
          k8s.gcr.io/conformance:v1.19.13],SizeBytes:229684398,},ContainerImage{Names:[grafana/grafana:8.0.5],SizeBytes:206381939,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb
          gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0],SizeBytes:195659796,},ContainerImage{Names:[quay.io/prometheus/prometheus:v2.28.1],SizeBytes:188863990,},ContainerImage{Names:[weaveworks/weaveexec:2.6.5],SizeBytes:149093862,},ContainerImage{Names:[envoyproxy/envoy:v1.19.0],SizeBytes:133745493,},ContainerImage{Names:[httpd@sha256:addd70e4ee83f3bc9a4c1c7c41e37927ba47faf639312fc936df3afad7926f5a
          httpd:2.4.39-alpine],SizeBytes:126894770,},ContainerImage{Names:[httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060
          httpd:2.4.38-alpine],SizeBytes:123781643,},ContainerImage{Names:[weaveworks/weave-kube:2.6.5],SizeBytes:123327967,},ContainerImage{Names:[k8s.gcr.io/kube-apiserver:v1.19.13],SizeBytes:118874525,},ContainerImage{Names:[replicated/ekco:v0.11.0],SizeBytes:117690299,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:17e61a0b9e498b6c73ed97670906be3d5a3ae394739c1bd5b619e1a004885cf0
          k8s.gcr.io/e2e-test-images/agnhost:2.20],SizeBytes:113869866,},ContainerImage{Names:[k8s.gcr.io/kube-controller-manager:v1.19.13],SizeBytes:110842269,},ContainerImage{Names:[k8s.gcr.io/kube-proxy:v1.19.13],SizeBytes:98938510,},ContainerImage{Names:[haproxy:2.4.2],SizeBytes:95448973,},ContainerImage{Names:[quay.io/kiwigrid/k8s-sidecar:1.12.2],SizeBytes:90352681,},ContainerImage{Names:[directxman12/k8s-prometheus-adapter-amd64:v0.8.4],SizeBytes:65885876,},ContainerImage{Names:[kurlsh/s3cmd:7f7dc75-20210331],SizeBytes:57614290,},ContainerImage{Names:[quay.io/prometheus/alertmanager:v0.22.2],SizeBytes:51591341,},ContainerImage{Names:[k8s.gcr.io/kube-scheduler:v1.19.13],SizeBytes:46498205,},ContainerImage{Names:[k8s.gcr.io/coredns:1.7.0],SizeBytes:45227747,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-operator:v0.49.0],SizeBytes:44484809,},ContainerImage{Names:[projectcontour/contour:v1.18.0],SizeBytes:42696704,},ContainerImage{Names:[k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.1.0],SizeBytes:37466503,},ContainerImage{Names:[sonobuoy/sonobuoy@sha256:d393e2c862fffd0823409594f3ab8bc2524b359d9e6313ae3f9edb5d3dfa56e1
          sonobuoy/sonobuoy:v0.53.2],SizeBytes:37400989,},ContainerImage{Names:[weaveworks/weave-npc:2.6.5],SizeBytes:36767037,},ContainerImage{Names:[registry:2.7.1],SizeBytes:26248135,},ContainerImage{Names:[quay.io/prometheus/node-exporter:v1.2.0],SizeBytes:21171468,},ContainerImage{Names:[nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
          nginx:1.14-alpine],SizeBytes:16032814,},ContainerImage{Names:[quay.io/prometheus-operator/prometheus-config-reloader:v0.49.0],SizeBytes:12425417,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nonewprivs@sha256:10066e9039219449fe3c81f38fe01928f87914150768ab81b62a468e51fa7411
          gcr.io/kubernetes-e2e-test-images/nonewprivs:1.0],SizeBytes:6757579,},ContainerImage{Names:[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc
          gcr.io/kubernetes-e2e-test-images/nautilus:1.0],SizeBytes:4753501,},ContainerImage{Names:[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796
          busybox:1.29],SizeBytes:1154361,},ContainerImage{Names:[k8s.gcr.io/pause:3.2],SizeBytes:682696,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}\nAug
          17 00:01:46.157: INFO: \nLogging kubelet events for node kyle-kurl\nAug
          17 00:01:46.160: INFO: \nLogging pods the kubelet thinks is on node kyle-kurl\nAug
          17 00:01:46.185: INFO: sonobuoy-e2e-job-587c54c6a51d4b83 started at 2021-08-16
          22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 17 00:01:46.185:
          INFO: \tContainer e2e ready: true, restart count 0\nAug 17 00:01:46.185:
          INFO: \tContainer sonobuoy-worker ready: true, restart count 0\nAug 17 00:01:46.185:
          INFO: etcd-kyle-kurl started at 2021-08-16 22:08:48 +0000 UTC (0+1 container
          statuses recorded)\nAug 17 00:01:46.185: INFO: \tContainer etcd ready: true,
          restart count 0\nAug 17 00:01:46.185: INFO: kube-apiserver-kyle-kurl started
          at 2021-08-16 22:08:48 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.185: INFO: \tContainer kube-apiserver ready: true, restart count
          0\nAug 17 00:01:46.185: INFO: kube-state-metrics-f97897479-p64b9 started
          at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer kube-state-metrics ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: prometheus-adapter-75c7788d57-bk7vm
          started at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer prometheus-adapter ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: prometheus-k8s-0 started at 2021-08-16
          23:59:08 +0000 UTC (1+2 container statuses recorded)\nAug 17 00:01:46.186:
          INFO: \tInit container init-config-reloader ready: true, restart count 0\nAug
          17 00:01:46.186: INFO: \tContainer config-reloader ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: \tContainer prometheus ready: true,
          restart count 0\nAug 17 00:01:46.186: INFO: coredns-f9fd979d6-vx9hq started
          at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer coredns ready: true, restart count 0\nAug
          17 00:01:46.186: INFO: kube-proxy-gpjcf started at 2021-08-16 22:08:56 +0000
          UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO: \tContainer
          kube-proxy ready: true, restart count 0\nAug 17 00:01:46.186: INFO: grafana-5b868476b6-657j2
          started at 2021-08-16 23:58:04 +0000 UTC (1+2 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tInit container grafana-sc-datasources ready: true,
          restart count 0\nAug 17 00:01:46.186: INFO: \tContainer grafana ready: true,
          restart count 0\nAug 17 00:01:46.186: INFO: \tContainer grafana-sc-dashboard
          ready: true, restart count 0\nAug 17 00:01:46.186: INFO: rook-ceph-osd-prepare-kyle-kurl-cqmkx
          started at 2021-08-16 23:59:11 +0000 UTC (0+2 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer copy-bins ready: false, restart count
          0\nAug 17 00:01:46.186: INFO: \tContainer provision ready: false, restart
          count 0\nAug 17 00:01:46.186: INFO: pod0-sched-preemption-low-priority started
          at <nil> (0+0 container statuses recorded)\nAug 17 00:01:46.186: INFO: rook-ceph-mon-a-6f9b75dbb9-rvssf
          started at 2021-08-16 23:58:04 +0000 UTC (1+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tInit container init-mon-fs ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: \tContainer mon ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: ekc-operator-5888598d79-rj7mm started
          at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer ekc-operator ready: true, restart count
          0\nAug 17 00:01:46.186: INFO: coredns-f9fd979d6-tzn8j started at 2021-08-16
          23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186:
          INFO: \tContainer coredns ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: rook-ceph-operator-747c86774c-m77bk started at 2021-08-16 23:58:04
          +0000 UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO:
          \tContainer rook-ceph-operator ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: contour-f85dd8bcb-jw9vk started at 2021-08-16 23:58:04 +0000 UTC (0+1
          container statuses recorded)\nAug 17 00:01:46.186: INFO: \tContainer contour
          ready: true, restart count 0\nAug 17 00:01:46.186: INFO: rook-discover-lk2rh
          started at 2021-08-16 23:57:58 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer rook-discover ready: true, restart count
          0\nAug 17 00:01:46.186: INFO: registry-5b5c4668f5-wzktn started at 2021-08-16
          23:58:04 +0000 UTC (1+2 container statuses recorded)\nAug 17 00:01:46.186:
          INFO: \tInit container restore ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: \tContainer registry ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: \tContainer registry-backup ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: alertmanager-prometheus-alertmanager-0 started at 2021-08-16 23:58:06
          +0000 UTC (0+2 container statuses recorded)\nAug 17 00:01:46.186: INFO:
          \tContainer alertmanager ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: \tContainer config-reloader ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: sonobuoy-systemd-logs-daemon-set-1f45972dd5a24001-jv96d started at
          2021-08-16 22:12:46 +0000 UTC (0+2 container statuses recorded)\nAug 17
          00:01:46.186: INFO: \tContainer sonobuoy-worker ready: true, restart count
          0\nAug 17 00:01:46.186: INFO: \tContainer systemd-logs ready: true, restart
          count 0\nAug 17 00:01:46.186: INFO: prometheus-node-exporter-8rt9q started
          at 2021-08-16 23:57:58 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer node-exporter ready: true, restart count
          0\nAug 17 00:01:46.186: INFO: rook-ceph-mgr-a-7c8fb8db97-fnncq started at
          2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug 17
          00:01:46.186: INFO: \tContainer mgr ready: true, restart count 0\nAug 17
          00:01:46.186: INFO: weave-net-p789g started at 2021-08-16 23:57:58 +0000
          UTC (0+2 container statuses recorded)\nAug 17 00:01:46.186: INFO: \tContainer
          weave ready: true, restart count 0\nAug 17 00:01:46.186: INFO: \tContainer
          weave-npc ready: true, restart count 1\nAug 17 00:01:46.186: INFO: contour-f85dd8bcb-l9g9l
          started at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer contour ready: true, restart count 0\nAug
          17 00:01:46.186: INFO: rook-ceph-agent-ptsv7 started at 2021-08-16 23:59:38
          +0000 UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO:
          \tContainer rook-ceph-agent ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: envoy-fvk8z started at 2021-08-16 23:58:38 +0000 UTC (1+2 container
          statuses recorded)\nAug 17 00:01:46.186: INFO: \tInit container envoy-initconfig
          ready: true, restart count 0\nAug 17 00:01:46.186: INFO: \tContainer envoy
          ready: true, restart count 0\nAug 17 00:01:46.186: INFO: \tContainer shutdown-manager
          ready: true, restart count 0\nAug 17 00:01:46.186: INFO: sonobuoy started
          at 2021-08-16 22:12:42 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer kube-sonobuoy ready: true, restart count
          0\nAug 17 00:01:46.186: INFO: rook-ceph-rgw-rook-ceph-store-a-55dbbfcbf5-csl7f
          started at 2021-08-16 23:58:04 +0000 UTC (0+1 container statuses recorded)\nAug
          17 00:01:46.186: INFO: \tContainer rgw ready: true, restart count 0\nAug
          17 00:01:46.186: INFO: kube-scheduler-kyle-kurl started at 2021-08-16 22:08:49
          +0000 UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO:
          \tContainer kube-scheduler ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: rook-ceph-osd-0-667b79b95b-hp9sv started at 2021-08-16 23:58:04 +0000
          UTC (2+1 container statuses recorded)\nAug 17 00:01:46.186: INFO: \tInit
          container config-init ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: \tInit container copy-bins ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: \tContainer osd ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: prometheus-operator-7f6d8fdc86-m62rh started at 2021-08-16 23:58:04
          +0000 UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO:
          \tContainer kube-prometheus-stack ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: kube-controller-manager-kyle-kurl started at 2021-08-16 22:08:48 +0000
          UTC (0+1 container statuses recorded)\nAug 17 00:01:46.186: INFO: \tContainer
          kube-controller-manager ready: true, restart count 0\nAug 17 00:01:46.186:
          INFO: registry-5b5c4668f5-kbffn started at 2021-08-16 23:58:04 +0000 UTC
          (1+2 container statuses recorded)\nAug 17 00:01:46.186: INFO: \tInit container
          restore ready: true, restart count 0\nAug 17 00:01:46.186: INFO: \tContainer
          registry ready: true, restart count 0\nAug 17 00:01:46.186: INFO: \tContainer
          registry-backup ready: true, restart count 0\nAug 17 00:01:46.239: INFO:
          \nLatency metrics for node kyle-kurl\nAug 17 00:01:46.239: INFO: Waiting
          up to 3m0s for all (but 0) nodes to be ready\nSTEP: Destroying namespace
          \"sched-preemption-7608\" for this suite.\n[AfterEach] [sig-scheduling]
          SchedulerPreemption [Serial]\n  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:77\n"
    
    